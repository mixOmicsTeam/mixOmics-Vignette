% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{array}
\usepackage{multirow}
\usepackage{wrapfig}
\usepackage{float}
\usepackage{colortbl}
\usepackage{pdflscape}
\usepackage{tabu}
\usepackage{threeparttable}
\usepackage{threeparttablex}
\usepackage[normalem]{ulem}
\usepackage{makecell}
\usepackage{xcolor}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{apalike}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={mixOmics Bookdown Vignette},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{mixOmics Bookdown Vignette}
\author{true}
\date{\today}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{preamble}{%
\chapter*{Preamble}\label{preamble}}
\addcontentsline{toc}{chapter}{Preamble}

If you are following our \href{https://study.unimelb.edu.au/find/short-courses/mixomics-r-essentials-for-biological-data-integration/\#course-specifics}{online course}, the following vignette will be useful as a complementary learning tool. This vignette also covers the essential use cases of various methods in this package for the general \texttt{mixOmcis} user. The below methods will be covered:

\begin{itemize}
\tightlist
\item
  (s)PCA,
\item
  PLS1 and PLS2,
\item
  (s)PLS-DA,
\item
  N-integration (multi-block sPLS-DA, aka. ``DIABLO''), and
\item
  P-integration (multi-group sPLS-DA, aka ``MINT'').
\end{itemize}

As outlined in \ref{01::outline}, this is not an exhaustive list of all the methods found within \texttt{mixOmics}. More information can be found at \href{http://mixomics.org/}{our website} and you can ask questions via our \href{https://mixomics-users.discourse.group/}{discourse forum}.

\begin{figure}
\centering
\includegraphics{InputFigures/MixOmicsAnalysesV2.png}
\caption{\label{fig:00-analyses-diagram}\textbf{Different types of analyses with mixOmics} \citep{mixomics}.The biological questions, the number of data sets to integrate, and the type of response variable, whether qualitative (classification), quantitative (regression), one (PLS1) or several (PLS) responses, all drive the choice of analytical method. All methods featured in this diagram include variable selection except rCCA. In N-integration, rCCA and PLS enable the integration of two quantitative data sets, whilst the block PLS methods (that derive from the methods from \citet{Ten11}) can integrate more than two data sets. In P-integration, our method MINT is based on multi-group PLS \citep{Esl14b}.The following activities cover some of these methods.}
\end{figure}

\hypertarget{01}{%
\chapter{Introduction}\label{01}}

\texttt{mixOmics} is an R toolkit dedicated to the exploration and integration of biological data sets with a specific focus on variable selection. The package currently includes more than twenty multivariate methodologies, mostly developed by the \texttt{mixOmics} team (see some of our references in \ref{01:pubs}). Originally, all methods were designed for omics data, however, their application is not limited to biological data only. Other applications where integration is required can be considered, but mostly for the case where the predictor variables are continuous (see also \ref{01:datatypes}).

In \texttt{mixOmics}, a strong focus is given to graphical representation to better translate and understand the relationships between the different data types and visualize the correlation structure at both sample and variable levels.

\hypertarget{01:datatypes}{%
\section{Input data}\label{01:datatypes}}

Note the data pre-processing requirements before analysing data with \texttt{mixOmics}:

\begin{itemize}
\item
  \textbf{Types of data}. Different types of biological data can be explored and integrated with \texttt{mixOmics}. Our methods can handle molecular features measured on a continuous scale (e.g.~microarray, mass spectrometry-based proteomics and metabolomics) or sequenced-based count data (RNA-seq, 16S, shotgun metagenomics) that become `continuous' data after pre-processing and normalisation.
\item
  \textbf{Normalisation}. The package does not handle normalisation as it is platform-specific and we cover a too wide variety of data! Prior to the analysis, we assume the data sets have been normalised using appropriate normalisation methods and pre-processed when applicable.
\item
  \textbf{Prefiltering}. While \texttt{mixOmics} methods can handle large data sets (several tens of thousands of predictors), we recommend pre-filtering the data to less than 10K predictor variables per data set, for example by using Median Absolute Deviation \citep{Ten16} for RNA-seq data, by removing consistently low counts in microbiome data sets \citep{Lec16} or by removing near-zero variance predictors. Such step aims to lessen the computational time during the parameter tuning process.
\item
  \textbf{Data format}.
  Our methods use matrix decomposition techniques. Therefore, the numeric data matrix or data frames have \(n\) observations or samples in rows and \(p\) predictors or variables (e.g.~genes, proteins, OTUs) in columns.
\item
  \textbf{Covariates}. In the current version of \texttt{mixOmics}, covariates that may confound the analysis are not included in the methods. We recommend correcting for those covariates beforehand using appropriate univariate or multivariate methods for batch effect removal. Contact us for more details as we are currently working on this aspect.
\end{itemize}

\hypertarget{methods}{%
\section{Methods}\label{methods}}

\hypertarget{01:methods}{%
\subsection{Some background knowledge}\label{01:methods}}

We list here the main methodological or theoretical concepts you need to know to be able to efficiently apply \texttt{mixOmics}:

\begin{itemize}
\item
  \textbf{Individuals, observations or samples}: the experimental units on which information are collected, e.g.~patients, cell lines, cells, faecal samples etc.
\item
  \textbf{Variables, predictors}: read-out measured on each sample, e.g.~gene (expression), protein or OTU (abundance), weight etc.
\item
  \textbf{Variance}: measures the spread of one variable. In our methods, we estimate the variance of components rather that variable read-outs. A high variance indicates that the data points are very spread out from the mean, and from one another (scattered).
\item
  \textbf{Covariance}: measures the strength of the relationship between two variables, i.e.~whether they co-vary. A high covariance value indicates a strong relationship, e.g.~weight and height in individuals frequently vary roughly in the same way; roughly, the heaviest are the tallest. A covariance value has no lower or upper bound.
\item
  \textbf{Correlation}: a standardized version of the covariance that is bounded by -1 and 1.
\item
  \textbf{Linear combination}: variables are combined by multiplying each of them by a coefficient and adding the results. A linear combination of height and weight could be \(2 * weight - 1.5 * height\) with the coefficients \(2\) and \(-1.5\) assigned with weight and height respectively.
\item
  \textbf{Component}: an artificial variable built from a linear combination of the observed variables in a given data set. Variable coefficients are optimally defined based on some statistical criterion. For example in Principal Component Analysis, the coefficients of a (principal) component are defined so as to maximise the variance of the component.
\item
  \textbf{Loadings}: variable coefficients used to define a component.
\item
  \textbf{Sample plot}: representation of the samples projected in a small space spanned (defined) by the components. Samples coordinates are determined by their components values or scores.
\item
  \textbf{Correlation circle plot}: representation of the variables in a space spanned by the components. Each variable coordinate is defined as the correlation between the original variable value and each component. A correlation circle plot enables to visualise the correlation between variables - negative or positive correlation, defined by the cosine angle between the centre of the circle and each variable point) and the contribution of each variable to each component - defined by the absolute value of the coordinate on each component. For this interpretation, data need to be centred and scaled (by default in most of our methods except PCA). For more details on this insightful graphic, see Figure 1 in \citep{Gon12}.
\item
  \textbf{Unsupervised analysis}: the method does not take into account any known sample groups and the analysis is exploratory. Examples of unsupervised methods covered in this vignette are Principal Component Analysis (PCA, Chapter \ref{pca}), Projection to Latent Structures (PLS, Chapter \ref{pls}), and also Canonical Correlation Analysis (CCA, not covered here but see \href{http://mixomics.org/methods/rcca/}{the website page}).
\item
  \textbf{Supervised analysis}: the method includes a vector indicating the class membership of each sample. The aim is to discriminate sample groups and perform sample class prediction. Examples of supervised methods covered in this vignette are PLS Discriminant Analysis (PLS-DA, Chapter \ref{plsda}), DIABLO (Chapter \ref{nInte}) and also MINT (Chapter \ref{pInte}).
\end{itemize}

If the above descriptions were not comprehensive enough and you have some more questions, feel free to explore the \href{http://mixomics.org/faq/glossary/}{glossary} on our website.

\hypertarget{01:overview}{%
\subsection{Overview}\label{01:overview}}

Here is an overview of the most widely used methods in \texttt{mixOmics} that will be further detailed in this vignette, with the exception of rCCA. We depict them along with the type of data set they can handle.

FIGURE 1: An overview of what quantity and type of dataset each method within mixOmics requires. Thin columns represent a single variable, while the larger blocks represent datasets of multiple samples and variables.

\begin{figure}[h]

{\centering \includegraphics[width=1\linewidth,]{InputFigures/Methods} 

}

\caption{List of methods in mixOmics, sparse indicates methods that perform variable selection}\label{fig:01-methods-diagram}
\end{figure}

\begin{figure}[h]

{\centering \includegraphics[width=1\linewidth,]{InputFigures/cheatsheet} 

}

\caption{Main functions and parameters of each method}\label{fig:01-cheatsheet}
\end{figure}

\hypertarget{01:pubs}{%
\subsection{Key publications}\label{01:pubs}}

The methods implemented in \texttt{mixOmics} are described in detail in the following publications. A more extensive list can be found at this \href{http://mixomics.org/a-propos/publications/}{link}.

\begin{itemize}
\item
  \textbf{Overview and recent integrative methods}: Rohart F., Gautier, B, Singh, A, Le Cao, K. A. mixOmics: an \href{http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005752}{R package for 'omics feature selection and multiple data integration}. \emph{PLoS Comput Biol} 13(11): e1005752.
\item
  \textbf{Graphical outputs for integrative methods}: \citep{Gon12} Gonzalez I., Le Cao K.-A., Davis, M.D.~and Dejean S. (2012) \href{https://biodatamining.biomedcentral.com/articles/10.1186/1756-0381-5-19}{Insightful graphical outputs to explore relationships between two omics data sets}. \emph{BioData Mining} 5:19.
\item
  \textbf{DIABLO}: Singh A, Gautier B, Shannon C, Vacher M, Rohart F, Tebbutt S, K-A. Le Cao. \href{https://www.biorxiv.org/content/early/2018/03/20/067611}{DIABLO - multi-omics data integration for biomarker discovery}.
\item
  \textbf{sparse PLS}: Le Cao K.-A., Martin P.G.P, Robert-Granie C. and Besse, P. (2009) \href{http://www.biomedcentral.com/1471-2105/10/34/}{Sparse Canonical Methods for Biological Data Integration: application to a cross-platform study}. \emph{BMC Bioinformatics}, 10:34.
\item
  \textbf{sparse PLS-DA}: Le Cao K.-A., Boitard S. and Besse P. (2011) \href{https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-12-253}{Sparse PLS Discriminant Analysis: biologically relevant feature selection and graphical displays for multiclass problems}. \emph{BMC Bioinformatics}, 22:253.
\item
  \textbf{Multilevel approach for repeated measurements}: Liquet B, Le Cao K-A, Hocini H, Thiebaut R (2012). \href{https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-13-325}{A novel approach for biomarker selection and the integration of repeated measures experiments from two assays}. \emph{BMC Bioinformatics}, 13:325
\item
  \textbf{sPLS-DA for microbiome data}: Le Cao K-A\(^*\), Costello ME \(^*\), Lakis VA , Bartolo F, Chua XY, Brazeilles R and Rondeau P. (2016) \href{http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0160169}{MixMC: Multivariate insights into Microbial Communities}.PLoS ONE 11(8): e0160169
\end{itemize}

\hypertarget{01:outline}{%
\section{Outline of this Vignette}\label{01:outline}}

\begin{itemize}
\tightlist
\item
  \textbf{Chapter \ref{02}}: details some practical aspects to get started
\item
  \textbf{Chapter \ref{03}}: Principal Components Analysis (PCA)
\item
  \textbf{Chapter \ref{04}}: Projection to Latent Structures (PLS)
\item
  \textbf{Chapter \ref{05}}: Projection to Latent Structure - Discriminant Analysis (PLS-DA)
\item
  \textbf{Chapter \ref{06}}: Integrative analysis for multiple data sets, across samples (namely DIABLO)
\item
  \textbf{Chapter \ref{07}}: Integrative analysis for multiple data, across features (namely MINT)
\end{itemize}

Each methods chapter has the following outline:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Type of biological question to be answered
\item
  Brief description of an illustrative data set
\item
  Principle of the method
\item
  Quick start of the method with the main functions and arguments
\item
  To go further: customized plots, additional graphical outputs, and tuning parameters
\item
  FAQ
\end{enumerate}

\hypertarget{other-methods-not-covered-in-this-vignette}{%
\section{Other methods not covered in this vignette}\label{other-methods-not-covered-in-this-vignette}}

Other methods not covered in this document are described on our website and the following references:

\begin{itemize}
\item
  \href{http://www.mixOmics.org}{regularised Canonical Correlation Analysis}, see the \textbf{Methods} and \textbf{Case study} tabs, and \citep{Gon08} that describes CCA for large data sets.
\item
  \href{http://www.mixOmics.org/mixmc}{Microbiome (16S, shotgun metagenomics) data analysis}, see also \citep{Lec16} and \href{http://mixomics.org/mixkernel}{kernel integration for microbiome data}. The latter is in collaboration with Drs J Mariette and Nathalie Villa-Vialaneix (INRA Toulouse, France), an example is provided for the Tara ocean metagenomics and environmental data, see also \citep{Mar17}.
\end{itemize}

\hypertarget{02}{%
\chapter{Let's get started}\label{02}}

\hypertarget{02:install}{%
\section{Installation}\label{02:install}}

First, download the latest \texttt{mixOmics} version from Bioconductor:

\begin{Shaded}
\begin{Highlighting}[]
\ControlFlowTok{if}\NormalTok{ (}\SpecialCharTok{!}\FunctionTok{requireNamespace}\NormalTok{(}\StringTok{"BiocManager"}\NormalTok{, }\AttributeTok{quietly =} \ConstantTok{TRUE}\NormalTok{))}
    \FunctionTok{install.packages}\NormalTok{(}\StringTok{"BiocManager"}\NormalTok{)}
\NormalTok{ BiocManager}\SpecialCharTok{::}\FunctionTok{install}\NormalTok{(}\StringTok{"mixOmics"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Alternatively, you can install the latest GitHub version of the package:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{BiocManager}\SpecialCharTok{::}\FunctionTok{install}\NormalTok{(}\StringTok{"mixOmicsTeam/mixOmics"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{mixOmics} package should directly import the following packages:
\texttt{igraph,\ rgl,\ ellipse,\ corpcor,\ RColorBrewer,\ plyr,\ parallel,\ dplyr,\ tidyr,\ reshape2,\ methods,\ matrixStats,\ rARPACK,\ gridExtra}.
\textbf{For Apple mac users:} if you are unable to install the imported package \texttt{rgl}, you will need to install the \href{https://www.xquartz.org}{XQuartz software} first.

\hypertarget{02:load-data}{%
\section{Load the package}\label{02:load-data}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(mixOmics)}
\end{Highlighting}
\end{Shaded}

Check that there is no error when loading the package, especially for the \texttt{rgl} library (see above).

\hypertarget{upload-data}{%
\section{Upload data}\label{upload-data}}

The examples we give in this vignette use data that are already part of the package. To upload your own data, check first that your working directory is set, then read your data from a \texttt{.txt} or \texttt{.csv} format, either by using \textbf{File \textgreater{} Import Dataset} in RStudio or via one of these command lines:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# from csv file}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{read.csv}\NormalTok{(}\StringTok{"your\_data.csv"}\NormalTok{, }\AttributeTok{row.names =} \DecValTok{1}\NormalTok{, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{)}

\CommentTok{\# from txt file}
\NormalTok{data }\OtherTok{\textless{}{-}} \FunctionTok{read.table}\NormalTok{(}\StringTok{"your\_data.txt"}\NormalTok{, }\AttributeTok{header =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

For more details about the arguments used to modify those functions, type \texttt{?read.csv} or \texttt{?read.table} in the R console.

\hypertarget{02:quick-start}{%
\section{\texorpdfstring{Quick start in \texttt{mixOmics}}{Quick start in mixOmics}}\label{02:quick-start}}

Each analysis should follow this workflow:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Run the method
\item
  Graphical representation of the samples
\item
  Graphical representation of the variables
\end{enumerate}

Then use your critical thinking and additional functions and visual tools to make sense of your data! (some of which are listed in \ref{01:overview}) and will be described in the next Chapters.

For instance, for Principal Components Analysis, we first load the data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{data}\NormalTok{(nutrimouse)}
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ nutrimouse}\SpecialCharTok{$}\NormalTok{gene}
\end{Highlighting}
\end{Shaded}

Then use the following steps:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{MyResult.pca }\OtherTok{\textless{}{-}} \FunctionTok{pca}\NormalTok{(X)  }\CommentTok{\# 1 Run the method}
\FunctionTok{plotIndiv}\NormalTok{(MyResult.pca) }\CommentTok{\# 2 Plot the samples}
\FunctionTok{plotVar}\NormalTok{(MyResult.pca)   }\CommentTok{\# 3 Plot the variables}
\end{Highlighting}
\end{Shaded}

This is only a first quick-start, there will be many avenues you can take to deepen your exploratory and integrative analyses. The package proposes several methods to perform variable, or feature selection to identify the relevant information from rather large omics data sets. The sparse methods are listed in the Table in \ref{01:overview}.

Following our example here, sparse PCA can be applied to select the top 5 variables contributing to each of the two components in PCA. The user specifies the number of variables to selected on each component, for example, here 5 variables are selected on each of the first two components (\texttt{keepX=c(5,5)}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{MyResult.spca }\OtherTok{\textless{}{-}} \FunctionTok{spca}\NormalTok{(X, }\AttributeTok{keepX=}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{)) }\CommentTok{\# 1 Run the method}
\FunctionTok{plotIndiv}\NormalTok{(MyResult.spca)               }\CommentTok{\# 2 Plot the samples}
\FunctionTok{plotVar}\NormalTok{(MyResult.spca)                 }\CommentTok{\# 3 Plot the variables}
\end{Highlighting}
\end{Shaded}

You can see know that we have considerably reduced the number of genes in the \texttt{plotVar} correlation circle plot.

Do not stop here! We are not done yet. You can enhance your analyses with the following:

\begin{itemize}
\item
  Have a look at our manual and each of the functions and their examples, e.g.~\texttt{?pca}, \texttt{?plotIndiv}, \texttt{?sPCA}, \ldots{}
\item
  Run the examples from the help file using the \texttt{example} function: \texttt{example(pca)}, \texttt{example(plotIndiv)}, \ldots{}
\item
  Have a look at our \href{http://www.mixomics.org}{website} that features many tutorials and case studies,
\item
  Keep reading this vignette, this is \emph{just the beginning!}
\end{itemize}

\hypertarget{03}{%
\chapter{\texorpdfstring{PCA on the \texttt{multidrug} study}{PCA on the multidrug study}}\label{03}}

To illustrate PCA and is variants, we will analyse the \texttt{multidrug} case study available in the package. This pharmacogenomic study investigates the patterns of drug activity in cancer cell lines \citep{Sza04}. These cell lines come from the \href{https://dtp.cancer.gov/discovery_development/nci-60/}{NCI-60 Human Tumor Cell Lines} established by the Developmental Therapeutics Program of the National Cancer Institute (NCI) to screen for the toxicity of chemical compound repositories in diverse cancer cell lines. NCI-60 includes cell lines derived from cancers of colorectal (7 cell lines), renal (8), ovarian (6), breast (8), prostate (2), lung (9) and central nervous system origin (6), as well as leukemia (6) and melanoma (8).

Two separate data sets (representing two types of measurements) on the same NCI-60 cancer cell lines are available in \texttt{multidrug} (see also \texttt{?multidrug}):

\begin{itemize}
\item
  \texttt{\$ABC.trans}: Contains the expression of 48 human ABC transporters measured by quantitative real-time PCR (RT-PCR) for each cell line.
\item
  \texttt{\$compound}: Contains the activity of 1,429 drugs expressed as GI50, which is the drug concentration that induces 50\% inhibition of cellular growth for the tested cell line.
\end{itemize}

Additional information will also be used in the outputs:

\begin{itemize}
\item
  \texttt{\$comp.name}: The names of the 1,429 compounds.
\item
  \texttt{\$cell.line}: Information on the cell line names (\texttt{\$Sample}) and the cell line types (\texttt{\$Class}).
\end{itemize}

In this activity, we illustrate PCA performed on the human ABC transporters \texttt{ABC.trans}, and sparse PCA on the compound data \texttt{compound}.

\hypertarget{03:load-data}{%
\section{Load the data}\label{03:load-data}}

The input data matrix \(\boldsymbol{X}\) is of size \(N\) samples in rows and \(P\) variables (e.g.~genes) in columns. We start with the \texttt{ABC.trans} data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(mixOmics)}
\FunctionTok{data}\NormalTok{(multidrug)}
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ multidrug}\SpecialCharTok{$}\NormalTok{ABC.trans}
\FunctionTok{dim}\NormalTok{(X) }\CommentTok{\# Check dimensions of data}
\end{Highlighting}
\end{Shaded}

\hypertarget{03:pca}{%
\section{Example: PCA}\label{03:pca}}

\hypertarget{03:pca-ncomp}{%
\subsection{Choose the number of components}\label{03:pca-ncomp}}

Contrary to the minimal code example, here we choose to also scale the variables for the reasons detailed earlier. The function \texttt{tune.pca()} calculates the cumulative proportion of explained variance for a large number of principal components (here we set \texttt{ncomp\ =\ 10}). A screeplot of the proportion of explained variance relative to the total amount of variance in the data for each principal component is output (Fig. \ref{fig:03-screeplot}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tune.pca.multi }\OtherTok{\textless{}{-}} \FunctionTok{tune.pca}\NormalTok{(X, }\AttributeTok{ncomp =} \DecValTok{10}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{TRUE}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(tune.pca.multi)}
\CommentTok{\# tune.pca.multidrug$cum.var       \# Outputs cumulative proportion of variance}
\end{Highlighting}
\end{Shaded}



From the numerical output (not shown here), we observe that the first two principal components explain \texttt{...round(tune.pca.multi\$cum.var{[}2{]}*100,\ 2)}\% of the total variance, and the first three principal components explain \texttt{...round(tune.pca.multi\$cum.var{[}3{]}*100,\ 2)}\% of the total variance. The rule of thumb for choosing the number of components is not so much to set a hard threshold based on the cumulative proportion of explained variance (as this is data-dependent), but to observe when a drop, or elbow, appears on the screeplot. The elbow indicates that the remaining variance is spread over many principal components and is not relevant in obtaining a low dimensional `snapshot' of the data. This is an empirical way of choosing the number of principal components to retain in the analysis. In this specific example we could choose between 2 to 3 components for the final PCA, however these criteria are highly subjective and the reader must keep in mind that visualisation becomes difficult above three dimensions.

\hypertarget{03:pca-final}{%
\subsection{PCA with fewer components}\label{03:pca-final}}

Based on the preliminary analysis above, we run a PCA with three components. Here we show additional input, such as whether to center or scale the variables.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final.pca.multi }\OtherTok{\textless{}{-}} \FunctionTok{pca}\NormalTok{(X, }\AttributeTok{ncomp =} \DecValTok{3}\NormalTok{, }\AttributeTok{center =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{TRUE}\NormalTok{)}
\CommentTok{\# final.pca.multi  \# Lists possible outputs}
\end{Highlighting}
\end{Shaded}

The output is similar to the tuning step above. Here the total variance in the data is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final.pca.multi}\SpecialCharTok{$}\NormalTok{var.tot}
\end{Highlighting}
\end{Shaded}

By summing the variance explained from all possible components, we would achieve the same amount of explained variance. The proportion of explained variance per component is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final.pca.multi}\SpecialCharTok{$}\NormalTok{prop\_expl\_var}\SpecialCharTok{$}\NormalTok{X}
\end{Highlighting}
\end{Shaded}

The cumulative proportion of variance explained can also be extracted (as displayed in Figure \ref{fig:03-screeplot}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final.pca.multi}\SpecialCharTok{$}\NormalTok{cum.var}
\end{Highlighting}
\end{Shaded}

\hypertarget{03:pca-vars}{%
\subsection{Identify the informative variables}\label{03:pca-vars}}

To calculate components, we use the variable coefficient weights indicated in the loading vectors. Therefore, the absolute value of the coefficients in the loading vectors inform us about the importance of each variable in contributing to the definition of each component. We can extract this information through the \texttt{selectVar()} function which ranks the most important variables in decreasing order according to their absolute loading weight value for each principal component.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Top variables on the first component only:}
\FunctionTok{head}\NormalTok{(}\FunctionTok{selectVar}\NormalTok{(final.pca.multi, }\AttributeTok{comp =} \DecValTok{1}\NormalTok{)}\SpecialCharTok{$}\NormalTok{value)}
\end{Highlighting}
\end{Shaded}

Note:

\begin{itemize}
\tightlist
\item
  \emph{Here the variables are not selected (all are included), but ranked according to their importance in defining each component.}
\end{itemize}

\hypertarget{03:pca-sample-plot}{%
\subsection{Sample plots}\label{03:pca-sample-plot}}

We project the samples into the space spanned by the principal components to visualise how the samples cluster and assess for biological or technical variation in the data. We colour the samples according to the cell line information available in \texttt{multidrug\$cell.line\$Class} by specifying the argument \texttt{group} (Fig. \ref{fig:03-pca-sample-plot}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotIndiv}\NormalTok{(final.pca.multi,}
          \AttributeTok{comp =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{),   }\CommentTok{\# Specify components to plot}
          \AttributeTok{ind.names =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# Show row names of samples}
          \AttributeTok{group =}\NormalTok{ multidrug}\SpecialCharTok{$}\NormalTok{cell.line}\SpecialCharTok{$}\NormalTok{Class,}
          \AttributeTok{title =} \StringTok{\textquotesingle{}ABC transporters, PCA comp 1 {-} 2\textquotesingle{}}\NormalTok{,}
          \AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{legend.title =} \StringTok{\textquotesingle{}Cell line\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



Because we have run PCA on three components, we can examine the third component, either by plotting the samples onto the principal components 1 and 3 (PC1 and PC3) in the code above (\texttt{comp\ =\ c(1,\ 3)}) or by using the 3D interactive plot (code shown below). The addition of the third principal component only seems to highlight a potential outlier (sample 8, not shown). Potentially, this sample could be removed from the analysis, or, noted when doing further downstream analysis. The removal of outliers should be exercised with great caution and backed up with several other types of analyses (e.g.~clustering) or graphical outputs (e.g.~boxplots, heatmaps, etc).

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Interactive 3D plot will load the rgl library.}
\FunctionTok{plotIndiv}\NormalTok{(final.pca.multi, }\AttributeTok{style =} \StringTok{\textquotesingle{}3d\textquotesingle{}}\NormalTok{,}
           \AttributeTok{group =}\NormalTok{ multidrug}\SpecialCharTok{$}\NormalTok{cell.line}\SpecialCharTok{$}\NormalTok{Class,}
          \AttributeTok{title =} \StringTok{\textquotesingle{}ABC transporters, PCA comp 1 {-} 3\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

These plots suggest that the largest source of variation explained by the first two components can be attributed to the \texttt{...colorize("pink",\ "melanoma")} cell line, while the third component highlights a single outlier sample. Hence, the interpretation of the following outputs should primarily focus on the first two components.

Note:

\begin{itemize}
\tightlist
\item
  \emph{Had we not scaled the data, the separation of the melanoma cell lines would have been more obvious with the addition of the third component, while PC1 and PC2 would have also highlighted the sample outliers 4 and 8. Thus, centering and scaling are important steps to take into account in PCA.}
\end{itemize}

\hypertarget{03:pca-variable-plot}{%
\subsection{Variable plot: correlation circle plot}\label{03:pca-variable-plot}}

Correlation circle plots indicate the contribution of each variable to each component using the \texttt{plotVar()} function, as well as the correlation between variables (indicated by a `cluster' of variables). Note that to interpret the latter, the variables need to be centered and scaled in PCA:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotVar}\NormalTok{(final.pca.multi, }\AttributeTok{comp =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{),}
        \AttributeTok{var.names =} \ConstantTok{TRUE}\NormalTok{,}
        \AttributeTok{cex =} \DecValTok{3}\NormalTok{,         }\CommentTok{\# To change the font size}
        \CommentTok{\# cutoff = 0.5,  \# For further cutoff}
        \AttributeTok{title =} \StringTok{\textquotesingle{}Multidrug transporter, PCA comp 1 {-} 2\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



The plot in Figure \ref{fig:03-pca-variable-plot} highlights a group of ABC transporters that contribute to PC1: \texttt{...colorize("orange",\ "ABCE1")}, and to some extent the group clustered with \texttt{...colorize("orange",\ "ABCB8")} that contributes positively to PC1, while \texttt{...colorize("green",\ "ABCA8")} contributes negatively. We also observe a group of transporters that contribute to both PC1 and PC2: the group clustered with \texttt{...colorize("pink",\ "ABCC2")} contributes positively to PC2 and negatively to PC1, and a cluster of \texttt{...colorize("yellow",\ "ABCC12")} and \texttt{...colorize("yellow",\ "ABCD2")} that contributes negatively to both PC1 and PC2. We observe that several transporters are inside the small circle. However, examining the third component (argument \texttt{comp\ =\ c(1,\ 3)}) does not appear to reveal further transporters that contribute to this third component. The additional argument \texttt{cutoff\ =\ 0.5} could further simplify this plot.

\hypertarget{03:pca-biplot}{%
\subsection{Biplot: samples and variables}\label{03:pca-biplot}}

A biplot allows us to display both samples and variables simultaneously to further understand their relationships. Samples are displayed as dots while variables are displayed at the tips of the arrows. Similar to correlation circle plots, data must be centered and scaled to interpret the correlation between variables (as a cosine angle between variable arrows).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{biplot}\NormalTok{(final.pca.multi, }\AttributeTok{group =}\NormalTok{ multidrug}\SpecialCharTok{$}\NormalTok{cell.line}\SpecialCharTok{$}\NormalTok{Class, }
       \AttributeTok{legend.title =} \StringTok{\textquotesingle{}Cell line\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



The biplot in Figure \ref{fig:03-pca-biplot} shows that the \texttt{...colorize("pink",\ "melanoma")} cell lines seem to be characterised by a subset of transporters such as the cluster around \texttt{...colorize("pink",\ "ABCC2")} as highlighted previously in Figure \ref{fig:03-pca-variable-plot}. Further examination of the data, such as boxplots (as shown in Fig. \ref{fig:03-pca-boxplot}), can further elucidate the transporter expression levels for these specific samples.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ABCC2.scale }\OtherTok{\textless{}{-}} \FunctionTok{scale}\NormalTok{(X[, }\StringTok{\textquotesingle{}ABCC2\textquotesingle{}}\NormalTok{], }\AttributeTok{center =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{boxplot}\NormalTok{(ABCC2.scale }\SpecialCharTok{\textasciitilde{}}
\NormalTok{        multidrug}\SpecialCharTok{$}\NormalTok{cell.line}\SpecialCharTok{$}\NormalTok{Class, }\AttributeTok{col =} \FunctionTok{color.mixo}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{9}\NormalTok{),}
        \AttributeTok{xlab =} \StringTok{\textquotesingle{}Cell lines\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}Expression levels, scaled\textquotesingle{}}\NormalTok{,}
        \FunctionTok{par}\NormalTok{(}\AttributeTok{cex.axis =} \FloatTok{0.5}\NormalTok{), }\CommentTok{\# Font size}
        \AttributeTok{main =} \StringTok{\textquotesingle{}ABCC2 transporter\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



\hypertarget{03:spca}{%
\section{Example: sparse PCA}\label{03:spca}}

In the \texttt{ABC.trans} data, there is only one missing value. Missing values can be handled by sPCA via the NIPALS algorithm . However, if the number of missing values is large, we recommend imputing them with NIPALS, as we describe in our website in www.mixOmics.org.

\hypertarget{03:spca-vars}{%
\subsection{Choose the number of variables to select}\label{03:spca-vars}}

First, we must decide on the number of components to evaluate. The previous tuning step indicated that \texttt{ncomp\ =\ 3} was sufficient to explain most of the variation in the data, which is the value we choose in this example. We then set up a grid of \texttt{keepX} values to test, which can be thin or coarse depending on the total number of variables. We set up the grid to be thin at the start, and coarse as the number of variables increases. The \texttt{ABC.trans} data includes a sufficient number of samples to perform repeated 5-fold cross-validation to define the number of folds and repeats (leave-one-out CV is also possible if the number of samples \(N\) is small by specifying \texttt{folds\ =} \(N\)). The computation may take a while if you are not using parallelisation (see additional parameters in \texttt{tune.spca()}), here we use a small number of repeats for illustrative purposes. We then plot the output of the tuning function.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{grid.keepX }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{seq}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{30}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\CommentTok{\# grid.keepX  \# To see the grid}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{30}\NormalTok{) }\CommentTok{\# For reproducibility with this handbook, remove otherwise}
\NormalTok{tune.spca.result }\OtherTok{\textless{}{-}} \FunctionTok{tune.spca}\NormalTok{(X, }\AttributeTok{ncomp =} \DecValTok{3}\NormalTok{, }
                              \AttributeTok{folds =} \DecValTok{5}\NormalTok{, }
                              \AttributeTok{test.keepX =}\NormalTok{ grid.keepX, }\AttributeTok{nrepeat =} \DecValTok{10}\NormalTok{) }

\CommentTok{\# Consider adding up to 50 repeats for more stable results}
\NormalTok{tune.spca.result}\SpecialCharTok{$}\NormalTok{choice.keepX}

\FunctionTok{plot}\NormalTok{(tune.spca.result)}
\end{Highlighting}
\end{Shaded}



The tuning function outputs the averaged correlation between predicted and actual components per \texttt{keepX} value for each component. It indicates the optimal number of variables to select for which the averaged correlation is maximised on each component. Figure \ref{fig:03-spca-tuning} shows that this is achieved when selecting \texttt{...tune.spca.result\$choice.keepX{[}1{]}} transporters on the first component, and \texttt{...tune.spca.result\$choice.keepX{[}2{]}} on the second. Given the drop in values in the averaged correlations for the third component, we decide to only retain two components.

Note:

\begin{itemize}
\tightlist
\item
  \emph{If the tuning results suggest a large number of variables to select that is close to the total number of variables, we can arbitrarily choose a much smaller selection size.}
\end{itemize}

\hypertarget{03:spca-final}{%
\subsection{Final sparse PCA}\label{03:spca-final}}

Based on the tuning above, we perform the final sPCA where the number of variables to select on each component is specified with the argument \texttt{keepX}. Arbitrary values can also be input if you would like to skip the tuning step for more exploratory analyses:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# By default center = TRUE, scale = TRUE}
\NormalTok{keepX.select }\OtherTok{\textless{}{-}}\NormalTok{ tune.spca.result}\SpecialCharTok{$}\NormalTok{choice.keepX[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{]}

\NormalTok{final.spca.multi }\OtherTok{\textless{}{-}} \FunctionTok{spca}\NormalTok{(X, }\AttributeTok{ncomp =} \DecValTok{2}\NormalTok{, }\AttributeTok{keepX =}\NormalTok{ keepX.select)}

\CommentTok{\# Proportion of explained variance:}
\NormalTok{final.spca.multi}\SpecialCharTok{$}\NormalTok{prop\_expl\_var}\SpecialCharTok{$}\NormalTok{X}
\end{Highlighting}
\end{Shaded}

Overall when considering two components, we lose approximately \texttt{...round(final.pca.multi\$cum.var{[}2{]}\ -\ cumsum(final.spca.multi\$prop\_expl\_var\$X){[}2{]},3)\ *\ 100} \% of explained variance compared to a full PCA, but the aim of this analysis is to identify key transporters driving the variation in the data, as we show below.

\hypertarget{03:spca-plots}{%
\subsection{Sample and variable plots}\label{03:spca-plots}}

We first examine the sPCA sample plot:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotIndiv}\NormalTok{(final.spca.multi,}
          \AttributeTok{comp =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{),   }\CommentTok{\# Specify components to plot}
          \AttributeTok{ind.names =} \ConstantTok{TRUE}\NormalTok{, }\CommentTok{\# Show row names of samples}
          \AttributeTok{group =}\NormalTok{ multidrug}\SpecialCharTok{$}\NormalTok{cell.line}\SpecialCharTok{$}\NormalTok{Class,}
          \AttributeTok{title =} \StringTok{\textquotesingle{}ABC transporters, sPCA comp 1 {-} 2\textquotesingle{}}\NormalTok{,}
          \AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{legend.title =} \StringTok{\textquotesingle{}Cell line\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



In Figure \ref{fig:03-spca-sample-plot}, component 2 in sPCA shows clearer separation of the \texttt{...colorize("pink",\ "melanoma")} samples compared to the full PCA. Component 1 is similar to the full PCA. Overall, this sample plot shows that little information is lost compared to a full PCA.

A biplot can also be plotted that only shows the selected transporters (Figure \ref{fig:03-spca-biplot}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{biplot}\NormalTok{(final.spca.multi, }\AttributeTok{group =}\NormalTok{ multidrug}\SpecialCharTok{$}\NormalTok{cell.line}\SpecialCharTok{$}\NormalTok{Class, }
       \AttributeTok{legend =}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



The correlation circle plot highlights variables that contribute to component 1 and component 2 (Fig. \ref{fig:03-spca-variable-plot}):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotVar}\NormalTok{(final.spca.multi, }\AttributeTok{comp =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{2}\NormalTok{), }\AttributeTok{var.names =} \ConstantTok{TRUE}\NormalTok{, }
        \AttributeTok{cex =} \DecValTok{3}\NormalTok{, }\CommentTok{\# To change the font size }
        \AttributeTok{title =} \StringTok{\textquotesingle{}Multidrug transporter, sPCA comp 1 {-} 2\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



The transporters selected by sPCA are amongst the most important ones in PCA. Those coloured in green in Figure \ref{fig:03-pca-variable-plot} (\texttt{...colorize("green",\ "ABCA9,\ ABCB5,\ ABCC2")} and \texttt{...colorize("green",\ "ABCD1")}) show an example of variables that contribute positively to component 2, but with a larger weight than in PCA. Thus, they appear as a clearer cluster in the top part of the correlation circle plot compared to PCA. As shown in the biplot in Figure \ref{fig:03-spca-biplot}, they contribute in explaining the variation in the \texttt{...colorize("pink",\ "melanoma")} samples.

We can extract the variable names and their positive or negative contribution to a given component (here 2), using the \texttt{selectVar()} function:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# On the first component, just a head}
\FunctionTok{head}\NormalTok{(}\FunctionTok{selectVar}\NormalTok{(final.spca.multi, }\AttributeTok{comp =} \DecValTok{2}\NormalTok{)}\SpecialCharTok{$}\NormalTok{value)}
\end{Highlighting}
\end{Shaded}

The loading weights can also be visualised with \texttt{plotLoading()}, where variables are ranked from the least important (top) to the most important (bottom) in Figure \ref{fig:03-spca-loading-plot}). Here on component 2:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotLoadings}\NormalTok{(final.spca.multi, }\AttributeTok{comp =} \DecValTok{2}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



\hypertarget{04}{%
\chapter{PLS on the liver toxicity study}\label{04}}

The data come from a liver toxicity study in which 64 male rats were exposed to non-toxic (50 or 150 mg/kg), moderately toxic (1500 mg/kg) or severely toxic (2000 mg/kg) doses of acetaminophen (paracetamol) \citep{Bus07}. Necropsy was performed at 6, 18, 24 and 48 hours after exposure and the mRNA was extracted from the liver. Ten clinical measurements of markers for liver injury are available for each subject. The microarray data contain expression levels of 3,116 genes. The data were normalised and preprocessed by \citet{Bus07}.

\texttt{liver\ toxicity} contains the following:

\begin{itemize}
\tightlist
\item
  \texttt{\$gene}: A data frame with 64 rows (rats) and 3116 columns (gene expression levels),
\item
  \texttt{\$clinic}: A data frame with 64 rows (same rats) and 10 columns (10 clinical variables),
\item
  \texttt{\$treatment}: A data frame with 64 rows and 4 columns, describe the different treatments, such as doses of acetaminophen and times of necropsy.
\end{itemize}

We can analyse these two data sets (genes and clinical measurements) using sPLS1, then sPLS2 with a regression mode to explain or predict the clinical variables with respect to the gene expression levels.

\hypertarget{04:load-data}{%
\section{Load the data}\label{04:load-data}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{devtools}\SpecialCharTok{::}\FunctionTok{load\_all}\NormalTok{(}\StringTok{"D:/My Files/Work/mixOmics/mixOmics"}\NormalTok{)}
\CommentTok{\#library(mixOmics)}
\FunctionTok{data}\NormalTok{(liver.toxicity)}
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ liver.toxicity}\SpecialCharTok{$}\NormalTok{gene}
\NormalTok{Y }\OtherTok{\textless{}{-}}\NormalTok{ liver.toxicity}\SpecialCharTok{$}\NormalTok{clinic}
\end{Highlighting}
\end{Shaded}

As we have discussed previously for integrative analysis, we need to ensure that the samples in the two data sets are in the same order, or matching, as we are performing data integration:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{head}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(}\FunctionTok{rownames}\NormalTok{(X), }\FunctionTok{rownames}\NormalTok{(Y)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   rownames.X. rownames.Y.
## 1       ID202       ID202
## 2       ID203       ID203
## 3       ID204       ID204
## 4       ID206       ID206
## 5       ID208       ID208
## 6       ID209       ID209
\end{verbatim}

\hypertarget{04:spls1}{%
\section{Example: sPLS1 regression}\label{04:spls1}}

We first start with a simple case scenario where we wish to explain one \(\boldsymbol Y\) variable with a combination of selected \(\boldsymbol X\) variables (transcripts). We choose the following clinical measurement which we denote as the \(\boldsymbol y\) single response variable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ liver.toxicity}\SpecialCharTok{$}\NormalTok{clinic[, }\StringTok{"ALB.g.dL."}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\hypertarget{04:spls1-ncomp}{%
\subsection{\texorpdfstring{Number of dimensions using the \(Q^2\) criterion}{Number of dimensions using the Q\^{}2 criterion}}\label{04:spls1-ncomp}}

Defining the `best' number of dimensions to explain the data requires we first launch a PLS1 model with a large number of components. Some of the outputs from the PLS1 object are then retrieved in the \texttt{perf()} function to calculate the \(Q^2\) criterion using repeated 10-fold cross-validation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tune.pls1.liver }\OtherTok{\textless{}{-}} \FunctionTok{pls}\NormalTok{(}\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{Y =}\NormalTok{ y, }\AttributeTok{ncomp =} \DecValTok{4}\NormalTok{, }\AttributeTok{mode =} \StringTok{\textquotesingle{}regression\textquotesingle{}}\NormalTok{)}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{33}\NormalTok{)  }\CommentTok{\# For reproducibility with this handbook, remove otherwise}
\NormalTok{Q2.pls1.liver }\OtherTok{\textless{}{-}} \FunctionTok{perf}\NormalTok{(tune.pls1.liver, }\AttributeTok{validation =} \StringTok{\textquotesingle{}Mfold\textquotesingle{}}\NormalTok{, }
                      \AttributeTok{folds =} \DecValTok{10}\NormalTok{, }\AttributeTok{nrepeat =} \DecValTok{5}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(Q2.pls1.liver, }\AttributeTok{criterion =} \StringTok{\textquotesingle{}Q2\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{Figures/PLS/04-spls1-ncomp-1} 

}

\caption{\textbf{\(Q^2\) criterion to choose the number of components in PLS1}. For each dimension added to the PLS model, the \(Q^2\) value is shown. The horizontal line of 0.0975 indicates the threshold below which adding a dimension may not be beneficial to improve accuracy in PLS.}\label{fig:04-spls1-ncomp}
\end{figure}



The plot in Figure \ref{fig:04-spls1-ncomp} shows that the \(Q^2\) value varies with the number of dimensions added to PLS1, with a decrease to negative values from 2 dimensions. Based on this plot we would choose only one dimension, but we will still add a second dimension for the graphical outputs.

Note:

\begin{itemize}
\tightlist
\item
  \emph{One dimension is not unusual given that we only include one \(\boldsymbol y\) variable in PLS1.}
\end{itemize}

\hypertarget{04:spls1-tuning}{%
\subsection{\texorpdfstring{Number of variables to select in \(\boldsymbol X\)}{Number of variables to select in \textbackslash boldsymbol X}}\label{04:spls1-tuning}}

We now set a grid of values - thin at the start, but also restricted to a small number of genes for a parsimonious model, which we will test for each of the two components in the \texttt{tune.spls()} function, using the MAE criterion.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Set up a grid of values: }
\NormalTok{list.keepX }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\SpecialCharTok{:}\DecValTok{10}\NormalTok{, }\FunctionTok{seq}\NormalTok{(}\DecValTok{15}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{5}\NormalTok{))     }

\CommentTok{\# list.keepX  \# Inspect the keepX grid}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{33}\NormalTok{)  }\CommentTok{\# For reproducibility with this handbook, remove otherwise}
\NormalTok{tune.spls1.MAE }\OtherTok{\textless{}{-}} \FunctionTok{tune.spls}\NormalTok{(X, y, }\AttributeTok{ncomp=} \DecValTok{2}\NormalTok{, }
                            \AttributeTok{test.keepX =}\NormalTok{ list.keepX, }
                            \AttributeTok{validation =} \StringTok{\textquotesingle{}Mfold\textquotesingle{}}\NormalTok{, }
                            \AttributeTok{folds =} \DecValTok{10}\NormalTok{,}
                            \AttributeTok{nrepeat =} \DecValTok{5}\NormalTok{, }
                            \AttributeTok{progressBar =} \ConstantTok{FALSE}\NormalTok{, }
                            \AttributeTok{measure =} \StringTok{\textquotesingle{}MAE\textquotesingle{}}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(tune.spls1.MAE)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{Figures/PLS/04-spls1-tuning-1} 

}

\caption{\textbf{Mean Absolute Error criterion to choose the number of variables to select in PLS1}, using repeated CV times for a grid of variables to select. The MAE increases with the addition of a second dimension \textcolor{orange}{comp 1 to 2}, suggesting that only one dimension is sufficient. The optimal \texttt{keepX} is indicated with a diamond.}\label{fig:04-spls1-tuning}
\end{figure}



Figure \ref{fig:04-spls1-tuning} confirms that one dimension is sufficient to reach minimal MAE. Based on the \texttt{tune.spls()} function we extract the final parameters:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{choice.ncomp }\OtherTok{\textless{}{-}}\NormalTok{ tune.spls1.MAE}\SpecialCharTok{$}\NormalTok{choice.ncomp}\SpecialCharTok{$}\NormalTok{ncomp}
\CommentTok{\# Optimal number of variables to select in X based on the MAE criterion}
\CommentTok{\# We stop at choice.ncomp}
\NormalTok{choice.keepX }\OtherTok{\textless{}{-}}\NormalTok{ tune.spls1.MAE}\SpecialCharTok{$}\NormalTok{choice.keepX[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{choice.ncomp]  }

\NormalTok{choice.ncomp}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{choice.keepX}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## comp1 
##    20
\end{verbatim}

Note:

\begin{itemize}
\tightlist
\item
  \emph{Other criterion could have been used and may bring different results. For example, when using \texttt{measure\ =\ \textquotesingle{}MSE}, the optimal \texttt{keepX} was rather unstable, and is often smaller than when using the MAE criterion. As we have highlighted before, there is some back and forth in the analyses to choose the criterion and parameters that best fit our biological question and interpretation.}
\end{itemize}

\hypertarget{04:spls1-final}{%
\subsection{Final sPLS1 model}\label{04:spls1-final}}

Here is our final model with the tuned parameters:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spls1.liver }\OtherTok{\textless{}{-}} \FunctionTok{spls}\NormalTok{(X, y, }\AttributeTok{ncomp =}\NormalTok{ choice.ncomp, }\AttributeTok{keepX =}\NormalTok{ choice.keepX, }
                    \AttributeTok{mode =} \StringTok{"regression"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The list of genes selected on component 1 can be extracted with the command line (not output here):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{selectVar}\NormalTok{(spls1.liver, }\AttributeTok{comp =} \DecValTok{1}\NormalTok{)}\SpecialCharTok{$}\NormalTok{X}\SpecialCharTok{$}\NormalTok{name}
\end{Highlighting}
\end{Shaded}

We can compare the amount of explained variance for the \(\boldsymbol X\) data set based on the sPLS1 (on 1 component) versus PLS1 (that was run on 4 components during the tuning step):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spls1.liver}\SpecialCharTok{$}\NormalTok{prop\_expl\_var}\SpecialCharTok{$}\NormalTok{X}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      comp1 
## 0.08150917
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tune.pls1.liver}\SpecialCharTok{$}\NormalTok{prop\_expl\_var}\SpecialCharTok{$}\NormalTok{X}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##      comp1      comp2      comp3      comp4 
## 0.11079101 0.14010577 0.21714518 0.06433377
\end{verbatim}

The amount of explained variance in \(\boldsymbol X\) is lower in sPLS1 than PLS1 for the first component. However, we will see in this case study that the Mean Squared Error Prediction is also lower (better) in sPLS1 compared to PLS1.

\hypertarget{04:spls1-sample-plots}{%
\subsection{Sample plots}\label{04:spls1-sample-plots}}

For further graphical outputs, we need to add a second dimension in the model, which can include the same number of \texttt{keepX} variables as in the first dimension. However, the interpretation should primarily focus on the first dimension. In Figure \ref{fig:04-spls1-sample-plot} we colour the samples according to the time of treatment and add symbols to represent the treatment dose. Recall however that such information was not included in the sPLS1 analysis.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spls1.liver.c2 }\OtherTok{\textless{}{-}} \FunctionTok{spls}\NormalTok{(X, y, }\AttributeTok{ncomp =} \DecValTok{2}\NormalTok{, }\AttributeTok{keepX =} \FunctionTok{c}\NormalTok{(}\FunctionTok{rep}\NormalTok{(choice.keepX, }\DecValTok{2}\NormalTok{)), }
                   \AttributeTok{mode =} \StringTok{"regression"}\NormalTok{)}

\FunctionTok{plotIndiv}\NormalTok{(spls1.liver.c2,}
          \AttributeTok{group =}\NormalTok{ liver.toxicity}\SpecialCharTok{$}\NormalTok{treatment}\SpecialCharTok{$}\NormalTok{Time.Group,}
          \AttributeTok{pch =} \FunctionTok{as.factor}\NormalTok{(liver.toxicity}\SpecialCharTok{$}\NormalTok{treatment}\SpecialCharTok{$}\NormalTok{Dose.Group),}
          \AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{legend.title =} \StringTok{\textquotesingle{}Time\textquotesingle{}}\NormalTok{, }\AttributeTok{legend.title.pch =} \StringTok{\textquotesingle{}Dose\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{Figures/PLS/04-spls1-sample-plot-1} 

}

\caption{\textbf{Sample plot from the PLS1 performed on the \texttt{liver.toxicity} data with two dimensions}. Components associated to each data set (or block) are shown. Focusing only on the projection of the sample on the first component shows that the genes selected in \(\boldsymbol X\) tend to explain the \textcolor{grey}{48h} length of treatment vs the earlier time points. This is somewhat in agreement with the levels of the \(\boldsymbol y\) variable. However, more insight can be obtained by plotting the first components only, as shown in Figure \ref{fig:04-spls1-sample-plot2}.}\label{fig:04-spls1-sample-plot}
\end{figure}



The alternative is to plot the component associated to the \(\boldsymbol X\) data set (here corresponding to a linear combination of the selected genes) vs.~the component associated to the \(\boldsymbol y\) variable (corresponding to the scaled \(\boldsymbol y\) variable in PLS1 with one dimension), or calculate the correlation between both components:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Define factors for colours matching plotIndiv above}
\NormalTok{time.liver }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(liver.toxicity}\SpecialCharTok{$}\NormalTok{treatment}\SpecialCharTok{$}\NormalTok{Time.Group, }
                     \AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}18\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}24\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}48\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}6\textquotesingle{}}\NormalTok{))}
\NormalTok{dose.liver }\OtherTok{\textless{}{-}} \FunctionTok{factor}\NormalTok{(liver.toxicity}\SpecialCharTok{$}\NormalTok{treatment}\SpecialCharTok{$}\NormalTok{Dose.Group, }
                     \AttributeTok{levels =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}50\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}150\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}1500\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}2000\textquotesingle{}}\NormalTok{))}
\CommentTok{\# Set up colours and symbols}
\NormalTok{col.liver }\OtherTok{\textless{}{-}} \FunctionTok{color.mixo}\NormalTok{(time.liver)}
\NormalTok{pch.liver }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(dose.liver)}

\FunctionTok{plot}\NormalTok{(spls1.liver}\SpecialCharTok{$}\NormalTok{variates}\SpecialCharTok{$}\NormalTok{X, spls1.liver}\SpecialCharTok{$}\NormalTok{variates}\SpecialCharTok{$}\NormalTok{Y,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}X component\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}y component / scaled y\textquotesingle{}}\NormalTok{,}
     \AttributeTok{col =}\NormalTok{ col.liver, }\AttributeTok{pch =}\NormalTok{ pch.liver)}
\FunctionTok{legend}\NormalTok{(}\StringTok{\textquotesingle{}topleft\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{color.mixo}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{), }\AttributeTok{legend =} \FunctionTok{levels}\NormalTok{(time.liver),}
       \AttributeTok{lty =} \DecValTok{1}\NormalTok{, }\AttributeTok{title =} \StringTok{\textquotesingle{}Time\textquotesingle{}}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{\textquotesingle{}bottomright\textquotesingle{}}\NormalTok{, }\AttributeTok{legend =} \FunctionTok{levels}\NormalTok{(dose.liver), }\AttributeTok{pch =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{,}
       \AttributeTok{title =} \StringTok{\textquotesingle{}Dose\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{Figures/PLS/04-spls1-sample-plot2-1} 

}

\caption{\textbf{Sample plot from the sPLS1 performed on the \texttt{liver.toxicity} data on one dimension}. A reduced representation of the 20 genes selected and combined in the \(\boldsymbol X\) component on the \(x-\)axis with respect to the \(\boldsymbol y\) component value (equivalent to the scaled values of \(\boldsymbol y\)) on the \(y-\)axis. We observe a separation between the high doses 1500 and 2000 mg/kg (symbols \(+\) and \(\times\)) at \textcolor{grey}{48h} and \textcolor{blue}{18h} while low and medium doses cluster in the middle of the plot. High doses for \textcolor{green}{6h} and \textcolor{blue}{18h} have high scores for both components.}\label{fig:04-spls1-sample-plot2}
\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cor}\NormalTok{(spls1.liver}\SpecialCharTok{$}\NormalTok{variates}\SpecialCharTok{$}\NormalTok{X, spls1.liver}\SpecialCharTok{$}\NormalTok{variates}\SpecialCharTok{$}\NormalTok{Y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           comp1
## comp1 0.7515489
\end{verbatim}



Figure \ref{fig:04-spls1-sample-plot2} is a reduced representation of a multivariate regression with PLS1. It shows that PLS1 effectively models a linear relationship between \(\boldsymbol y\) and the combination of the 20 genes selected in \(\boldsymbol X\).

\hypertarget{04:spls1-perf}{%
\subsection{Performance assessment of sPLS1}\label{04:spls1-perf}}

The performance of the final model can be assessed with the \texttt{perf()} function, using repeated cross-validation (CV). Because a single performance value has little meaning, we propose to compare the performances of a full PLS1 model (with no variable selection) with our sPLS1 model based on the MSEP (other criteria can be used):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{33}\NormalTok{)  }\CommentTok{\# For reproducibility with this handbook, remove otherwise}

\CommentTok{\# PLS1 model and performance}
\NormalTok{pls1.liver }\OtherTok{\textless{}{-}} \FunctionTok{pls}\NormalTok{(X, y, }\AttributeTok{ncomp =}\NormalTok{ choice.ncomp, }\AttributeTok{mode =} \StringTok{"regression"}\NormalTok{)}
\NormalTok{perf.pls1.liver }\OtherTok{\textless{}{-}} \FunctionTok{perf}\NormalTok{(pls1.liver, }\AttributeTok{validation =} \StringTok{"Mfold"}\NormalTok{, }\AttributeTok{folds =}\DecValTok{10}\NormalTok{, }
                   \AttributeTok{nrepeat =} \DecValTok{5}\NormalTok{, }\AttributeTok{progressBar =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{perf.pls1.liver}\SpecialCharTok{$}\NormalTok{measures}\SpecialCharTok{$}\NormalTok{MSEP}\SpecialCharTok{$}\NormalTok{summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   feature comp      mean         sd
## 1       Y    1 0.7281681 0.04134627
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# To extract values across all repeats:}
\CommentTok{\# perf.pls1.liver$measures$MSEP$values}

\CommentTok{\# sPLS1 performance}
\NormalTok{perf.spls1.liver }\OtherTok{\textless{}{-}} \FunctionTok{perf}\NormalTok{(spls1.liver, }\AttributeTok{validation =} \StringTok{"Mfold"}\NormalTok{, }\AttributeTok{folds =} \DecValTok{10}\NormalTok{, }
                   \AttributeTok{nrepeat =} \DecValTok{5}\NormalTok{, }\AttributeTok{progressBar =} \ConstantTok{FALSE}\NormalTok{)}
\NormalTok{perf.spls1.liver}\SpecialCharTok{$}\NormalTok{measures}\SpecialCharTok{$}\NormalTok{MSEP}\SpecialCharTok{$}\NormalTok{summary}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##   feature comp      mean         sd
## 1       Y    1 0.5958565 0.02697727
\end{verbatim}

The MSEP is lower with sPLS1 compared to PLS1, indicating that the \(\boldsymbol{X}\) variables selected (listed above with \texttt{selectVar()}) can be considered as a good linear combination of predictors to explain \(\boldsymbol y\).

\hypertarget{04:spls2}{%
\section{Example: PLS2 regression}\label{04:spls2}}

PLS2 is a more complex problem than PLS1, as we are attempting to fit a linear combination of a subset of \(\boldsymbol{Y}\) variables that are maximally covariant with a combination of \(\boldsymbol{X}\) variables. The sparse variant allows for the selection of variables from both data sets.

As a reminder, here are the dimensions of the \(\boldsymbol{Y}\) matrix that includes clinical parameters associated with liver failure.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{dim}\NormalTok{(Y)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 64 10
\end{verbatim}

\hypertarget{04:spls2-ncomp}{%
\subsection{\texorpdfstring{Number of dimensions using the \(Q^2\) criterion}{Number of dimensions using the Q\^{}2 criterion}}\label{04:spls2-ncomp}}

Similar to PLS1, we first start by tuning the number of components to select by using the \texttt{perf()} function and the \(Q^2\) criterion using repeated cross-validation.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tune.pls2.liver }\OtherTok{\textless{}{-}} \FunctionTok{pls}\NormalTok{(}\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{Y =}\NormalTok{ Y, }\AttributeTok{ncomp =} \DecValTok{5}\NormalTok{, }\AttributeTok{mode =} \StringTok{\textquotesingle{}regression\textquotesingle{}}\NormalTok{)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{33}\NormalTok{)  }\CommentTok{\# For reproducibility with this handbook, remove otherwise}
\NormalTok{Q2.pls2.liver }\OtherTok{\textless{}{-}} \FunctionTok{perf}\NormalTok{(tune.pls2.liver, }\AttributeTok{validation =} \StringTok{\textquotesingle{}Mfold\textquotesingle{}}\NormalTok{, }\AttributeTok{folds =} \DecValTok{10}\NormalTok{, }
                      \AttributeTok{nrepeat =} \DecValTok{5}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(Q2.pls2.liver, }\AttributeTok{criterion =} \StringTok{\textquotesingle{}Q2.total\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{Figures/PLS/04-spls2-ncomp-1} 

}

\caption{\textbf{\(Q^2\) criterion to choose the number of components in PLS2}. For each component added to the PLS2 model, the averaged \(Q^2\) across repeated cross-validation is shown, with the horizontal line of 0.0975 indicating the threshold below which the addition of a dimension may not be beneficial to improve accuracy.}\label{fig:04-spls2-ncomp}
\end{figure}



Figure \ref{fig:s04-spls2-ncomp} shows that one dimension should be sufficient in PLS2. We will include a second dimension in the graphical outputs, whilst focusing our interpretation on the first dimension.

Note:

\begin{itemize}
\tightlist
\item
  \emph{Here we chose repeated cross-validation, however, the conclusions were similar for \texttt{nrepeat\ =\ 1}.}
\end{itemize}

\hypertarget{04:spls2-tuning}{%
\subsection{\texorpdfstring{Number of variables to select in both \(\boldsymbol X\) and \(\boldsymbol Y\)}{Number of variables to select in both \textbackslash boldsymbol X and \textbackslash boldsymbol Y}}\label{04:spls2-tuning}}

Using the \texttt{tune.spls()} function, we can perform repeated cross-validation to obtain some indication of the number of variables to select. We show an example of code below which may take some time to run (see \texttt{?tune.spls()} to use parallel computing). We had refined the grid of tested values as the tuning function tended to favour a very small signature. Hence we decided to constrain the start of the grid to 3 for a more insightful signature. Both \texttt{measure\ =\ \textquotesingle{}cor} and \texttt{RSS} gave similar signature sizes, but this observation might differ for other case studies.

The optimal parameters can be output, along with a plot showing the tuning results, as shown in Figure \ref{fig:04-spls2-tuning}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This code may take several min to run, parallelisation option is possible}
\NormalTok{list.keepX }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FunctionTok{seq}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{50}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\NormalTok{list.keepY }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\SpecialCharTok{:}\DecValTok{10}\NormalTok{)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{33}\NormalTok{)  }\CommentTok{\# For reproducibility with this handbook, remove otherwise}
\NormalTok{tune.spls.liver }\OtherTok{\textless{}{-}} \FunctionTok{tune.spls}\NormalTok{(X, Y, }\AttributeTok{test.keepX =}\NormalTok{ list.keepX, }
                             \AttributeTok{test.keepY =}\NormalTok{ list.keepY, }\AttributeTok{ncomp =} \DecValTok{2}\NormalTok{, }
                             \AttributeTok{nrepeat =} \DecValTok{1}\NormalTok{, }\AttributeTok{folds =} \DecValTok{10}\NormalTok{, }\AttributeTok{mode =} \StringTok{\textquotesingle{}regression\textquotesingle{}}\NormalTok{, }
                             \AttributeTok{measure =} \StringTok{\textquotesingle{}cor\textquotesingle{}}\NormalTok{, }
                            \CommentTok{\#   the following uses two CPUs for faster computation}
                            \CommentTok{\# it can be commented out}
                            \AttributeTok{BPPARAM =}\NormalTok{ BiocParallel}\SpecialCharTok{::}\FunctionTok{SnowParam}\NormalTok{(}\AttributeTok{workers =} \DecValTok{14}\NormalTok{)}
\NormalTok{                            )}

\FunctionTok{plot}\NormalTok{(tune.spls.liver)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.6\linewidth]{Figures/PLS/04-spls2-tuning-1} 

}

\caption{\textbf{Tuning plot for sPLS2}. For every grid value of \texttt{keepX} and \texttt{keepY}, the averaged correlation coefficients between the \(\boldsymbol t\) and \(\boldsymbol u\) components are shown across repeated CV, with optimal values (here corresponding to the highest mean correlation) indicated in a \textcolor{green}{green square} for each dimension and data set.}\label{fig:04-spls2-tuning}
\end{figure}



\hypertarget{04:spls2-final}{%
\subsection{Final sPLS2 model}\label{04:spls2-final}}

Here is our final model with the tuned parameters for our sPLS2 regression analysis. Note that if you choose to not run the tuning step, you can still decide to set the parameters of your choice here.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Optimal parameters}
\NormalTok{choice.keepX }\OtherTok{\textless{}{-}}\NormalTok{ tune.spls.liver}\SpecialCharTok{$}\NormalTok{choice.keepX}
\NormalTok{choice.keepY }\OtherTok{\textless{}{-}}\NormalTok{ tune.spls.liver}\SpecialCharTok{$}\NormalTok{choice.keepY}
\NormalTok{choice.ncomp }\OtherTok{\textless{}{-}} \FunctionTok{length}\NormalTok{(choice.keepX)}

\NormalTok{spls2.liver }\OtherTok{\textless{}{-}} \FunctionTok{spls}\NormalTok{(X, Y, }\AttributeTok{ncomp =}\NormalTok{ choice.ncomp, }
                   \AttributeTok{keepX =}\NormalTok{ choice.keepX,}
                   \AttributeTok{keepY =}\NormalTok{ choice.keepY,}
                   \AttributeTok{mode =} \StringTok{"regression"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{04:spls2-variance}{%
\subsubsection{Numerical outputs}\label{04:spls2-variance}}

The amount of explained variance can be extracted for each dimension and each data set:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{spls2.liver}\SpecialCharTok{$}\NormalTok{prop\_expl\_var}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## $X
##      comp1      comp2 
## 0.19955426 0.08131033 
## 
## $Y
##     comp1     comp2 
## 0.3650105 0.2172909
\end{verbatim}

\hypertarget{04:spls2-variables}{%
\subsubsection{Importance variables}\label{04:spls2-variables}}

The selected variables can be extracted from the \texttt{selectVar()} function, for example for the \(\boldsymbol X\) data set, with either their \texttt{\$name} or the loading \texttt{\$value} (not output here):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{selectVar}\NormalTok{(spls2.liver, }\AttributeTok{comp =} \DecValTok{1}\NormalTok{)}\SpecialCharTok{$}\NormalTok{X}\SpecialCharTok{$}\NormalTok{value}
\end{Highlighting}
\end{Shaded}

The VIP measure is exported for all variables in \(\boldsymbol X\), here we only subset those that were selected (non null loading value) for component 1:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{vip.spls2.liver }\OtherTok{\textless{}{-}} \FunctionTok{vip}\NormalTok{(spls2.liver)}
\CommentTok{\# just a head}
\FunctionTok{head}\NormalTok{(vip.spls2.liver[}\FunctionTok{selectVar}\NormalTok{(spls2.liver, }\AttributeTok{comp =} \DecValTok{1}\NormalTok{)}\SpecialCharTok{$}\NormalTok{X}\SpecialCharTok{$}\NormalTok{name,}\DecValTok{1}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## A_42_P620915  A_43_P14131 A_42_P578246  A_43_P11724 A_42_P840776 A_42_P675890 
##     20.10394     18.76841     14.50085     14.03470     13.37657     12.82384
\end{verbatim}

The (full) output shows that most \(\boldsymbol X\) variables that were selected are important for explaining \(\boldsymbol Y\), since their VIP is greater than 1.

We can examine how frequently each variable is selected when we subsample the data using the \texttt{perf()} function to measure how stable the signature is (Table \ref{tab:spls2stability}). The same could be output for other components and the \(\boldsymbol Y\) data set.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{perf.spls2.liver }\OtherTok{\textless{}{-}} \FunctionTok{perf}\NormalTok{(spls2.liver, }\AttributeTok{validation =} \StringTok{\textquotesingle{}Mfold\textquotesingle{}}\NormalTok{, }\AttributeTok{folds =} \DecValTok{10}\NormalTok{, }\AttributeTok{nrepeat =} \DecValTok{5}\NormalTok{)}
\CommentTok{\# Extract stability}
\NormalTok{stab.spls2.liver.comp1 }\OtherTok{\textless{}{-}}\NormalTok{ perf.spls2.liver}\SpecialCharTok{$}\NormalTok{features}\SpecialCharTok{$}\NormalTok{stability.X}\SpecialCharTok{$}\NormalTok{comp1}
\CommentTok{\# Averaged stability of the X selected features across CV runs, as shown in Table}
\NormalTok{stab.spls2.liver.comp1[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{choice.keepX[}\DecValTok{1}\NormalTok{]]}

\CommentTok{\# We extract the stability measures of only the variables selected in spls2.liver}
\NormalTok{extr.stab.spls2.liver.comp1 }\OtherTok{\textless{}{-}}\NormalTok{ stab.spls2.liver.comp1[}\FunctionTok{selectVar}\NormalTok{(spls2.liver, }
                                                                  \AttributeTok{comp =}\DecValTok{1}\NormalTok{)}\SpecialCharTok{$}\NormalTok{X}\SpecialCharTok{$}\NormalTok{name]}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[t]{l|r}
\caption{\label{tab:04-spls2-stab-table}Stability measure (occurence of selection) of the bottom 20 variables from X selected with sPLS2 across repeated 10-fold subsampling on component 1.}\\
\hline
  & x\\
\hline
A\_43\_P11570 & 0.94\\
\hline
A\_42\_P681650 & 0.98\\
\hline
A\_42\_P586270 & 0.88\\
\hline
A\_43\_P12400 & 0.98\\
\hline
A\_42\_P769476 & 0.94\\
\hline
A\_42\_P814010 & 0.96\\
\hline
A\_42\_P484423 & 0.90\\
\hline
A\_42\_P636498 & 0.90\\
\hline
A\_43\_P12806 & 0.94\\
\hline
A\_43\_P12832 & 0.90\\
\hline
A\_42\_P610788 & 0.74\\
\hline
A\_42\_P470649 & 0.86\\
\hline
A\_43\_P15425 & 0.78\\
\hline
A\_42\_P681533 & 0.86\\
\hline
A\_42\_P669630 & 0.64\\
\hline
A\_43\_P14864 & 0.62\\
\hline
A\_42\_P698740 & 0.52\\
\hline
A\_42\_P550264 & 0.40\\
\hline
A\_43\_P10006 & 0.44\\
\hline
A\_42\_P469551 & 0.34\\
\hline
\end{longtable}

We recommend to mainly focus on the interpretation of the most stable selected variables (with a frequency of occurrence greater than 0.8).

\hypertarget{04:spls2-plots}{%
\subsubsection{Graphical outputs}\label{04:spls2-plots}}

\textbf{Sample plots.}
Using the \texttt{plotIndiv()} function, we display the sample and metadata information using the arguments \texttt{group} (colour) and \texttt{pch} (symbol) to better understand the similarities between samples modelled with sPLS2.

The plot on the left hand side corresponds to the projection of the samples from the \(\boldsymbol X\) data set (gene expression) and the plot on the right hand side the \(\boldsymbol Y\) data set (clinical variables).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotIndiv}\NormalTok{(spls2.liver, }\AttributeTok{ind.names =} \ConstantTok{FALSE}\NormalTok{, }
          \AttributeTok{group =}\NormalTok{ liver.toxicity}\SpecialCharTok{$}\NormalTok{treatment}\SpecialCharTok{$}\NormalTok{Time.Group, }
          \AttributeTok{pch =} \FunctionTok{as.factor}\NormalTok{(liver.toxicity}\SpecialCharTok{$}\NormalTok{treatment}\SpecialCharTok{$}\NormalTok{Dose.Group), }
          \AttributeTok{col.per.group =} \FunctionTok{color.mixo}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{),}
          \AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{legend.title =} \StringTok{\textquotesingle{}Time\textquotesingle{}}\NormalTok{, }
          \AttributeTok{legend.title.pch =} \StringTok{\textquotesingle{}Dose\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{Figures/PLS/04-spls2-sample-plot-1} 

}

\caption{\textbf{Sample plot for sPLS2 performed on the \texttt{liver.toxicity} data}. Samples are projected into the space spanned by the components associated to each data set (or block). We observe some agreement between the data sets, and a separation of the 1500 and 2000 mg doses (\(+\) and \(\times\)) in the \textcolor{blue}{18h}, \textcolor{orange}{24h} time points, and the \textcolor{grey}{48h} time point.}\label{fig:04-spls2-sample-plot}
\end{figure}



From Figure \ref{fig:04-spls2-sample-plot} we observe an effect of low vs.~high doses of acetaminophen (component 1) as well as time of necropsy (component 2). There is some level of agreement between the two data sets, but it is not perfect!

If you run an sPLS with three dimensions, you can consider the 3D \texttt{plotIndiv()} by specifying \texttt{style\ =\ \textquotesingle{}3d} in the function.

The \texttt{plotArrow()} option is useful in this context to visualise the level of agreement between data sets. Recall that in this plot:

\begin{itemize}
\tightlist
\item
  The start of the arrow indicates the location of the sample in the \(\boldsymbol X\) projection space,
\item
  The end of the arrow indicates the location of the (same) sample in the \(\boldsymbol Y\) projection space,
\item
  Long arrows indicate a disagreement between the two projected spaces.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotArrow}\NormalTok{(spls2.liver, }\AttributeTok{ind.names =} \ConstantTok{FALSE}\NormalTok{, }
          \AttributeTok{group =}\NormalTok{ liver.toxicity}\SpecialCharTok{$}\NormalTok{treatment}\SpecialCharTok{$}\NormalTok{Time.Group,}
          \AttributeTok{col.per.group =} \FunctionTok{color.mixo}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{),}
          \AttributeTok{legend.title =} \StringTok{\textquotesingle{}Time.Group\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{Figures/PLS/04-spls2-arrow-plot-1} 

}

\caption{\textbf{Arrow plot from the sPLS2 performed on the \texttt{liver.toxicity} data}. The start of the arrow indicates the location of a given sample in the space spanned by the components associated to the gene data set, and the tip of the arrow the location of that same sample in the space spanned by the components associated to the clinical data set. We observe large shifts for \textcolor{blue}{18h}, \textcolor{orange}{24} and \textcolor{grey}{48h} samples for the high doses, however the clusters of samples remain the same, as we observed in Figure \ref{fig:04-spls2-sample-plot}.}\label{fig:04-spls2-arrow-plot}
\end{figure}



In Figure \ref{fig:04-spls2-arrow-plot} we observe that specific groups of samples seem to be located far apart from one data set to the other, indicating a potential discrepancy between the information extracted. However the groups of samples according to either dose or treatment remains similar.

\textbf{Variable plots.}
Correlation circle plots illustrate the correlation structure between the two types of variables. To display only the name of the variables from the \(\boldsymbol{Y}\) data set, we use the argument \texttt{var.names\ =\ c(FALSE,\ TRUE)} where each boolean indicates whether the variable names should be output for each data set. We also modify the size of the font, as shown in Figure \ref{fig:04-spls2-variable-plot}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotVar}\NormalTok{(spls2.liver, }\AttributeTok{cex =} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{), }\AttributeTok{var.names =} \FunctionTok{c}\NormalTok{(}\ConstantTok{FALSE}\NormalTok{, }\ConstantTok{TRUE}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{Figures/PLS/04-spls2-variable-plot-1} 

}

\caption{\textbf{Correlation circle plot from the sPLS2 performed on the \texttt{liver.toxicity} data}. The plot highlights correlations \emph{within} selected genes (their names are not indicated here), \emph{within} selected clinical parameters, and correlations \emph{between} genes and clinical parameters on each dimension of sPLS2. This plot should be interpreted in relation to Figure \ref{fig:04-spls2-sample-plot} to better understand how the expression levels of these molecules may characterise specific sample groups.}\label{fig:04-spls2-variable-plot}
\end{figure}



To display variable names that are different from the original data matrix (e.g.~gene ID), we set the argument \texttt{var.names} as a list for each type of label, with geneBank ID for the \(\boldsymbol X\) data set, and \texttt{TRUE} for the \(\boldsymbol Y\) data set:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotVar}\NormalTok{(spls2.liver,}
        \AttributeTok{var.names =} \FunctionTok{list}\NormalTok{(}\AttributeTok{X.label =}\NormalTok{ liver.toxicity}\SpecialCharTok{$}\NormalTok{gene.ID[,}\StringTok{\textquotesingle{}geneBank\textquotesingle{}}\NormalTok{],}
        \AttributeTok{Y.label =} \ConstantTok{TRUE}\NormalTok{), }\AttributeTok{cex =} \FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{Figures/PLS/04-spls2-variable-plot2-1} 

}

\caption{\textbf{Correlation circle plot from the sPLS2 performed on the \texttt{liver.toxicity} data}. A variant of Figure \ref{fig:04-spls2-variable-plot} with gene names that are available in \texttt{\$gene.ID} (Note: some gene names are missing).}\label{fig:04-spls2-variable-plot2}
\end{figure}



The correlation circle plots highlight the contributing variables that, together, explain the covariance between the two data sets. In addition, specific subsets of molecules can be further investigated, and in relation with the sample group they may characterise. The latter can be examined with additional plots (for example boxplots with respect to known sample groups and expression levels of specific variables, as we showed in the PCA case study previously. The next step would be to examine the validity of the biological relationship between the clusters of genes with some of the clinical variables that we observe in this plot.

A 3D plot is also available in \texttt{plotVar()} with the argument \texttt{style\ =\ \textquotesingle{}3d}. It requires an sPLS2 model with at least three dimensions.

Other plots are available to complement the information from the correlation circle plots, such as Relevance networks and Clustered Image Maps (CIMs), as described in Module 2.

The network in sPLS2 displays only the variables selected by sPLS, with an additional \texttt{cutoff} similarity value argument (absolute value between 0 and 1) to improve interpretation. Because Rstudio sometimes struggles with the margin size of this plot, we can either launch \texttt{X11()} prior to plotting the network, or use the arguments \texttt{save} and \texttt{name.save} as shown below:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Define red and green colours for the edges}
\NormalTok{color.edge }\OtherTok{\textless{}{-}} \FunctionTok{color.GreenRed}\NormalTok{(}\DecValTok{50}\NormalTok{)}

\CommentTok{\# X11()  \# To open a new window for Rstudio}
\FunctionTok{network}\NormalTok{(spls2.liver, }\AttributeTok{comp =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{,}
        \AttributeTok{cutoff =} \FloatTok{0.7}\NormalTok{,}
        \AttributeTok{shape.node =} \FunctionTok{c}\NormalTok{(}\StringTok{"rectangle"}\NormalTok{, }\StringTok{"circle"}\NormalTok{),}
        \AttributeTok{color.node =} \FunctionTok{c}\NormalTok{(}\StringTok{"cyan"}\NormalTok{, }\StringTok{"pink"}\NormalTok{),}
        \AttributeTok{color.edge =}\NormalTok{ color.edge,}
        \CommentTok{\# To save the plot, otherwise comment out:}
        \AttributeTok{save =} \StringTok{\textquotesingle{}pdf\textquotesingle{}}\NormalTok{, }\AttributeTok{name.save =} \StringTok{\textquotesingle{}network\_liver\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{network_liver} 

}

\caption{\textbf{Network representation from the sPLS2 performed on the \texttt{liver.toxicity} data}. The networks are bipartite, where each edge links a \textcolor{turquoise}{gene} (rectangle) to a \textcolor{pink}{clinical} variable (circle) node, according to a similarity matrix described in Module 2. Only variables selected by sPLS2 on the two dimensions are represented and are further filtered here according to a \texttt{cutoff} argument (optional).}\label{fig:04-spls2-network2}
\end{figure}



Figure \ref{fig:04-spls2-network2} shows two distinct groups of variables. The first cluster groups four clinical parameters that are mostly positively associated with selected genes. The second group includes one clinical parameter negatively associated with other selected genes. These observations are similar to what was observed in the correlation circle plot in Figure \ref{fig:04-spls2-variable-plot}.

Note:

\begin{itemize}
\tightlist
\item
  \emph{Whilst the edges and nodes in the network do not change, the appearance might be different from one run to another as it relies on a random process to use the space as best as possible (using the \texttt{igraph} R package \citet{csa06}).}
\end{itemize}

The Clustered Image Map also allows us to visualise correlations between variables. Here we choose to represent the variables selected on the two dimensions and we save the plot as a pdf figure.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# X11()  \# To open a new window if the graphic is too large}
\FunctionTok{cim}\NormalTok{(spls2.liver, }\AttributeTok{comp =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }\AttributeTok{xlab =} \StringTok{"clinic"}\NormalTok{, }\AttributeTok{ylab =} \StringTok{"genes"}\NormalTok{,}
    \CommentTok{\# To save the plot, otherwise comment out:}
    \AttributeTok{save =} \StringTok{\textquotesingle{}pdf\textquotesingle{}}\NormalTok{, }\AttributeTok{name.save =} \StringTok{\textquotesingle{}cim\_liver\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{cim_liver} 

}

\caption{\textbf{Clustered Image Map from the sPLS2 performed on the \texttt{liver.toxicity} data}. The plot displays the similarity values (as described in Module 2) between the \(\boldsymbol X\) and \(\boldsymbol Y\) variables selected across two dimensions, and clustered with a complete Euclidean distance method.}\label{fig:04-spls2-cim2}
\end{figure}



The CIM in Figure \ref{fig:04-spls2-cim2} shows that the clinical variables can be separated into three clusters, each of them either positively or negatively associated with two groups of genes. This is similar to what we have observed in Figure \ref{fig:04-spls2-variable-plot}. We would give a similar interpretation to the relevance network, had we also used a \texttt{cutoff} threshold in \texttt{cim()}.

Note:

\begin{itemize}
\tightlist
\item
  \emph{A biplot for PLS objects is also available.}
\end{itemize}

\hypertarget{04:spls2-perf}{%
\subsubsection{Performance}\label{04:spls2-perf}}

To finish, we assess the performance of sPLS2. As an element of comparison, we consider sPLS2 and PLS2 that includes all variables, to give insights into the different methods.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Comparisons of final models (PLS, sPLS)}

\DocumentationTok{\#\# PLS}
\NormalTok{pls.liver }\OtherTok{\textless{}{-}} \FunctionTok{pls}\NormalTok{(X, Y, }\AttributeTok{mode =} \StringTok{\textquotesingle{}regression\textquotesingle{}}\NormalTok{, }\AttributeTok{ncomp =} \DecValTok{2}\NormalTok{)}
\NormalTok{perf.pls.liver }\OtherTok{\textless{}{-}}  \FunctionTok{perf}\NormalTok{(pls.liver, }\AttributeTok{validation =} \StringTok{\textquotesingle{}Mfold\textquotesingle{}}\NormalTok{, }\AttributeTok{folds =} \DecValTok{10}\NormalTok{, }
                        \AttributeTok{nrepeat =} \DecValTok{5}\NormalTok{)}

\DocumentationTok{\#\# Performance for the sPLS model ran earlier}
\NormalTok{perf.spls.liver }\OtherTok{\textless{}{-}}  \FunctionTok{perf}\NormalTok{(spls2.liver, }\AttributeTok{validation =} \StringTok{\textquotesingle{}Mfold\textquotesingle{}}\NormalTok{, }\AttributeTok{folds =} \DecValTok{10}\NormalTok{, }
                         \AttributeTok{nrepeat =} \DecValTok{5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), perf.pls.liver}\SpecialCharTok{$}\NormalTok{measures}\SpecialCharTok{$}\NormalTok{cor.upred}\SpecialCharTok{$}\NormalTok{summary}\SpecialCharTok{$}\NormalTok{mean, }
     \AttributeTok{col =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, }\AttributeTok{pch =} \DecValTok{16}\NormalTok{, }
     \AttributeTok{ylim =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.6}\NormalTok{,}\DecValTok{1}\NormalTok{), }\AttributeTok{xaxt =} \StringTok{\textquotesingle{}n\textquotesingle{}}\NormalTok{,}
     \AttributeTok{xlab =} \StringTok{\textquotesingle{}Component\textquotesingle{}}\NormalTok{, }\AttributeTok{ylab =} \StringTok{\textquotesingle{}t or u Cor\textquotesingle{}}\NormalTok{, }
     \AttributeTok{main =} \StringTok{\textquotesingle{}s/PLS performance based on Correlation\textquotesingle{}}\NormalTok{)}
\FunctionTok{axis}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{)  }\CommentTok{\# X{-}axis label}
\FunctionTok{points}\NormalTok{(perf.pls.liver}\SpecialCharTok{$}\NormalTok{measures}\SpecialCharTok{$}\NormalTok{cor.tpred}\SpecialCharTok{$}\NormalTok{summary}\SpecialCharTok{$}\NormalTok{mean, }\AttributeTok{col =} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\AttributeTok{pch =} \DecValTok{16}\NormalTok{)}
\FunctionTok{points}\NormalTok{(perf.spls.liver}\SpecialCharTok{$}\NormalTok{measures}\SpecialCharTok{$}\NormalTok{cor.upred}\SpecialCharTok{$}\NormalTok{summary}\SpecialCharTok{$}\NormalTok{mean, }\AttributeTok{col =} \StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, }\AttributeTok{pch =} \DecValTok{17}\NormalTok{)}
\FunctionTok{points}\NormalTok{(perf.spls.liver}\SpecialCharTok{$}\NormalTok{measures}\SpecialCharTok{$}\NormalTok{cor.tpred}\SpecialCharTok{$}\NormalTok{summary}\SpecialCharTok{$}\NormalTok{mean, }\AttributeTok{col =} \StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\AttributeTok{pch =} \DecValTok{17}\NormalTok{)}
\FunctionTok{legend}\NormalTok{(}\StringTok{\textquotesingle{}bottomleft\textquotesingle{}}\NormalTok{, }\AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}blue\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}red\textquotesingle{}}\NormalTok{), }
       \AttributeTok{pch =} \FunctionTok{c}\NormalTok{(}\DecValTok{16}\NormalTok{, }\DecValTok{16}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{17}\NormalTok{), }\FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}u PLS\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}t PLS\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}u sPLS\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}t sPLS\textquotesingle{}}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}

{\centering \includegraphics[width=0.7\linewidth]{Figures/PLS/04-spls2-perf2-1} 

}

\caption{\textbf{Comparison of the performance of PLS2 and sPLS2}, based on the correlation between the actual and predicted components \(\boldsymbol{t,u}\) associated to each data set for each component.}\label{fig:04-spls2-perf2}
\end{figure}



We extract the correlation between the actual and predicted components \(\boldsymbol{t,u}\) associated to each data set in Figure \ref{fig:04-spls2-perf2}. The correlation remains high on the first dimension, even when variables are selected. On the second dimension the correlation coefficients are equivalent or slightly lower in sPLS compared to PLS. Overall this performance comparison indicates that the variable selection in sPLS still retains relevant information compared to a model that includes all variables.

Note:

\begin{itemize}
\tightlist
\item
  \emph{Had we run a similar procedure but based on the RSS, we would have observed a lower RSS for sPLS compared to PLS.}
\end{itemize}

\hypertarget{plsda}{%
\chapter{PLS-DA on the SRBCT case study}\label{plsda}}

The Small Round Blue Cell Tumours (SRBCT) data set from \citep{Kha01} includes the expression levels of 2,308 genes measured on 63 samples. The samples are divided into four classes: 8 Burkitt Lymphoma (BL), 23 Ewing Sarcoma (EWS), 12 neuroblastoma (NB), and 20 rhabdomyosarcoma (RMS). The data are directly available in a processed and normalised format from the \texttt{mixOmics} package and contains the following:

\begin{itemize}
\item
  \texttt{\$gene}: A data frame with 63 rows and 2,308 columns. These are the expression levels of 2,308 genes in 63 subjects,
\item
  \texttt{\$class}: A vector containing the class of tumour for each individual (4 classes in total),
\item
  \texttt{\$gene.name}: A data frame with 2,308 rows and 2 columns containing further information on the genes.
\end{itemize}

More details can be found in \texttt{?srbct}. We will illustrate PLS-DA and sPLS-DA which are suited for large biological data sets where the aim is to identify molecular signatures, as well as classify samples. We will analyse the gene expression levels of \texttt{srbct\$gene} to discover which genes may best discriminate the 4 groups of tumours.

\hypertarget{plsda:load}{%
\section{Load the data}\label{plsda:load}}

We first load the data from the package. We then set up the data so that \(\boldsymbol X\) is the gene expression matrix and \(\boldsymbol y\) is the factor indicating sample class membership. \(\boldsymbol y\) will be transformed into a dummy matrix \(\boldsymbol Y\) inside the function. We also check that the dimensions are correct and match both \(\boldsymbol X\) and \(\boldsymbol y\):

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(mixOmics)}
\FunctionTok{data}\NormalTok{(srbct)}
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ srbct}\SpecialCharTok{$}\NormalTok{gene}

\CommentTok{\# Outcome y that will be internally coded as dummy:}
\NormalTok{Y }\OtherTok{\textless{}{-}}\NormalTok{ srbct}\SpecialCharTok{$}\NormalTok{class }
\FunctionTok{dim}\NormalTok{(X); }\FunctionTok{length}\NormalTok{(Y)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(Y)}
\end{Highlighting}
\end{Shaded}

\hypertarget{ex:plsda}{%
\section{Example: PLS-DA}\label{ex:plsda}}

\hypertarget{initial-exploration-with-pca}{%
\subsection{Initial exploration with PCA}\label{initial-exploration-with-pca}}

As covered in Module 3, PCA is a useful tool to explore the gene expression data and to assess for sample similarities between tumour types. Remember that PCA is an unsupervised approach, but we can colour the samples by their class to assist in interpreting the PCA (Figure \ref{fig:plsda-pca}). Here we center (default argument) and scale the data:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{pca.srbct }\OtherTok{\textless{}{-}} \FunctionTok{pca}\NormalTok{(X, }\AttributeTok{ncomp =} \DecValTok{3}\NormalTok{, }\AttributeTok{scale =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{plotIndiv}\NormalTok{(pca.srbct, }\AttributeTok{group =}\NormalTok{ srbct}\SpecialCharTok{$}\NormalTok{class, }\AttributeTok{ind.names =} \ConstantTok{FALSE}\NormalTok{,}
          \AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{, }
          \AttributeTok{title =} \StringTok{\textquotesingle{}SRBCT, PCA comp 1 {-} 2\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



We observe almost no separation between the different tumour types in the PCA sample plot, with perhaps the exception of the \texttt{...colorize("grey",\ "NB")} samples that tend to cluster with other samples. This preliminary exploration teaches us two important findings:

\begin{itemize}
\tightlist
\item
  The major source of variation is not attributable to tumour type, but an unknown source (we tend to observe clusters of samples but those are not explained by tumour type).
\item
  We need a more `directed' (supervised) analysis to separate the tumour types, and we should expect that the amount of variance explained by the dimensions in PLS-DA analysis will be small.
\end{itemize}

\hypertarget{number-of-components-in-pls-da}{%
\subsection{Number of components in PLS-DA}\label{number-of-components-in-pls-da}}

The \texttt{perf()} function evaluates the performance of PLS-DA - i.e., its ability to rightly classify `new' samples into their tumour category using repeated cross-validation. We initially choose a large number of components (here \texttt{ncomp\ =\ 10}) and assess the model as we gradually increase the number of components. Here we use 3-fold CV repeated 10 times. In Module 2, we provided further guidelines on how to choose the \texttt{folds} and \texttt{nrepeat} parameters:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plsda.srbct }\OtherTok{\textless{}{-}} \FunctionTok{plsda}\NormalTok{(X,Y, }\AttributeTok{ncomp =} \DecValTok{10}\NormalTok{)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{30}\NormalTok{) }\CommentTok{\# For reproducibility with this handbook, remove otherwise}
\NormalTok{perf.plsda.srbct }\OtherTok{\textless{}{-}} \FunctionTok{perf}\NormalTok{(plsda.srbct, }\AttributeTok{validation =} \StringTok{\textquotesingle{}Mfold\textquotesingle{}}\NormalTok{, }\AttributeTok{folds =} \DecValTok{3}\NormalTok{, }
                  \AttributeTok{progressBar =} \ConstantTok{FALSE}\NormalTok{,  }\CommentTok{\# Set to TRUE to track progress}
                  \AttributeTok{nrepeat =} \DecValTok{10}\NormalTok{)         }\CommentTok{\# We suggest nrepeat = 50}

\FunctionTok{plot}\NormalTok{(perf.plsda.srbct, }\AttributeTok{sd =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{legend.position =} \StringTok{\textquotesingle{}horizontal\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



From the classification performance output presented in Figure \ref{fig:plsda-perf} (also discussed in detail in Module 2), we observe that:

\begin{itemize}
\item
  There are some slight differences between the overall and balanced error rates (BER) with BER \textgreater{} overall, suggesting that minority classes might be ignored from the classification task when considering the overall performance (\texttt{summary(Y)} shows that BL only includes 8 samples). In general the trend is the same, however, and for further tuning with sPLS-DA we will consider the BER.
\item
  The error rate decreases and reaches a minimum for \texttt{ncomp\ =\ 3} for the \texttt{max.dist} distance. These parameters will be included in further analyses.
\end{itemize}

Notes:

\begin{itemize}
\tightlist
\item
  \emph{PLS-DA is an iterative model, where each component is orthogonal to the previous and gradually aims to build more discrimination between sample classes. We should always regard a final PLS-DA (with specified \texttt{ncomp}) as a `compounding' model (i.e.~PLS-DA with component 3 includes the trained model on the previous two components).}
\item
  \emph{We advise to use at least 50 repeats, and choose the number of folds that are appropriate for the sample size of the data set, as shown in Figure \ref{fig:plsda-perf}).}
\end{itemize}

Additional numerical outputs from the performance results are listed and can be reported as performance measures (not output here):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{perf.plsda.srbct}
\end{Highlighting}
\end{Shaded}

\hypertarget{PLSDA:final:perf}{%
\subsection{Final PLS-DA model}\label{PLSDA:final:perf}}

We now run our final PLS-DA model that includes three components:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final.plsda.srbct }\OtherTok{\textless{}{-}} \FunctionTok{plsda}\NormalTok{(X,Y, }\AttributeTok{ncomp =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We output the sample plots for the dimensions of interest (up to three). By default, the samples are coloured according to their class membership. We also add confidence ellipses (\texttt{ellipse\ =\ TRUE}, confidence level set to 95\% by default, see the argument \texttt{ellipse.level}) in Figure \ref{fig:plsda-plotindiv}. A 3D plot could also be insightful (use the argument \texttt{type\ =\ \textquotesingle{}3D\textquotesingle{}}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotIndiv}\NormalTok{(final.plsda.srbct, }\AttributeTok{ind.names =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{legend=}\ConstantTok{TRUE}\NormalTok{,}
          \AttributeTok{comp=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }\AttributeTok{ellipse =} \ConstantTok{TRUE}\NormalTok{, }
          \AttributeTok{title =} \StringTok{\textquotesingle{}PLS{-}DA on SRBCT comp 1{-}2\textquotesingle{}}\NormalTok{,}
          \AttributeTok{X.label =} \StringTok{\textquotesingle{}PLS{-}DA comp 1\textquotesingle{}}\NormalTok{, }\AttributeTok{Y.label =} \StringTok{\textquotesingle{}PLS{-}DA comp 2\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotIndiv}\NormalTok{(final.plsda.srbct, }\AttributeTok{ind.names =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{legend=}\ConstantTok{TRUE}\NormalTok{,}
          \AttributeTok{comp=}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\AttributeTok{ellipse =} \ConstantTok{TRUE}\NormalTok{, }
          \AttributeTok{title =} \StringTok{\textquotesingle{}PLS{-}DA on SRBCT comp 2{-}3\textquotesingle{}}\NormalTok{,}
          \AttributeTok{X.label =} \StringTok{\textquotesingle{}PLS{-}DA comp 2\textquotesingle{}}\NormalTok{, }\AttributeTok{Y.label =} \StringTok{\textquotesingle{}PLS{-}DA comp 3\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



We can observe improved clustering according to tumour subtypes, compared with PCA. This is to be expected since the PLS-DA model includes the class information of each sample. We observe some discrimination between the \texttt{...colorize("grey",\ "NB")} and \texttt{...colorize("orange",\ "BL")} samples vs.~the others on the first component (x-axis), and \texttt{...colorize("blue",\ "EWS")} and \texttt{...colorize("green",\ "RMS")} vs.~the others on the second component (y-axis). From the \texttt{plotIndiv()} function, the axis labels indicate the amount of variation explained per component. However, the interpretation of this amount is \emph{not as important} as in PCA, as PLS-DA aims to maximise the covariance between components associated to \(\boldsymbol X\) and \(\boldsymbol Y\), rather than the variance \(\boldsymbol X\).

\hypertarget{plsda:perf}{%
\subsection{Classification performance}\label{plsda:perf}}

We can rerun a more extensive performance evaluation with more repeats for our final model:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{30}\NormalTok{) }\CommentTok{\# For reproducibility with this handbook, remove otherwise}
\NormalTok{perf.final.plsda.srbct }\OtherTok{\textless{}{-}} \FunctionTok{perf}\NormalTok{(final.plsda.srbct, }\AttributeTok{validation =} \StringTok{\textquotesingle{}Mfold\textquotesingle{}}\NormalTok{, }
                               \AttributeTok{folds =} \DecValTok{3}\NormalTok{, }
                               \AttributeTok{progressBar =} \ConstantTok{FALSE}\NormalTok{, }\CommentTok{\# TRUE to track progress}
                               \AttributeTok{nrepeat =} \DecValTok{50}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

Retaining only the BER and the \texttt{max.dist}, numerical outputs of interest include the final overall performance for 3 components:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{perf.final.plsda.srbct}\SpecialCharTok{$}\NormalTok{error.rate}\SpecialCharTok{$}\NormalTok{BER[, }\StringTok{\textquotesingle{}max.dist\textquotesingle{}}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

As well as the error rate per class across each component:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{perf.final.plsda.srbct}\SpecialCharTok{$}\NormalTok{error.rate.class}\SpecialCharTok{$}\NormalTok{max.dist}
\end{Highlighting}
\end{Shaded}

From this output, we can see that the first component tends to classify EWS and NB better than the other classes. As components 2 and then 3 are added, the classification improves for all classes. However we see a slight increase in classification error in component 3 for EWS and RMS while BL is perfectly classified. A permutation test could also be conducted to conclude about the significance of the differences between sample groups, but is not currently implemented in the package.

\hypertarget{ex:plsda:background}{%
\subsection{Background prediction}\label{ex:plsda:background}}

A prediction background can be added to the sample plot by calculating a background surface first, before overlaying the sample plot (Figure \ref{fig:plsda-background}, see Extra Reading material, or \texttt{?background.predict}). We give an example of the code below based on the maximum prediction distance:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{background.max }\OtherTok{\textless{}{-}} \FunctionTok{background.predict}\NormalTok{(final.plsda.srbct, }
                                     \AttributeTok{comp.predicted =} \DecValTok{2}\NormalTok{,}
                                     \AttributeTok{dist =} \StringTok{\textquotesingle{}max.dist\textquotesingle{}}\NormalTok{) }

\FunctionTok{plotIndiv}\NormalTok{(final.plsda.srbct, }\AttributeTok{comp =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{, }\AttributeTok{group =}\NormalTok{ srbct}\SpecialCharTok{$}\NormalTok{class,}
          \AttributeTok{ind.names =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{title =} \StringTok{\textquotesingle{}Maximum distance\textquotesingle{}}\NormalTok{,}
          \AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{,  }\AttributeTok{background =}\NormalTok{ background.max)}
\end{Highlighting}
\end{Shaded}



Figure \ref{fig:plsda-background} shows the differences in prediction according to the prediction distance, and can be used as a further diagnostic tool for distance choice. It also highlights the characteristics of the distances. For example the \texttt{max.dist} is a linear distance, whereas both \texttt{centroids.dist} and \texttt{mahalanobis.dist} are non linear. Our experience has shown that as discrimination of the classes becomes more challenging, the complexity of the distances (from maximum to Mahalanobis distance) should increase, see details in the Extra reading material.

\hypertarget{ex:splsda}{%
\section{Example: sPLS-DA}\label{ex:splsda}}

In high-throughput experiments, we expect that many of the \texttt{...ncol(X)} genes in \(\boldsymbol X\) are noisy or uninformative to characterise the different classes. An sPLS-DA analysis will help refine the sample clusters and select a small subset of variables relevant to discriminate each class.

\hypertarget{plsda:result:numvar}{%
\subsection{Number of variables to select}\label{plsda:result:numvar}}

We estimate the classification error rate with respect to the number of selected variables in the model with the function \texttt{tune.splsda()}. The tuning is being performed one component at a time inside the function and the optimal number of variables to select is automatically retrieved after each component run, as described in Module 2.

Previously, we determined the number of components to be \texttt{ncomp\ =\ 3} with PLS-DA. Here we set \texttt{ncomp\ =\ 4} to further assess if this would be the case for a sparse model, and use 5-fold cross validation repeated 10 times. We also choose the maximum prediction distance.

Note:

\begin{itemize}
\tightlist
\item
  \emph{For a thorough tuning step, the following code should be repeated 10 - 50 times and the error rate is averaged across the runs. You may obtain slightly different results below for this reason.}
\end{itemize}

We first define a grid of \texttt{keepX} values. For example here, we define a fine grid at the start, and then specify a coarser, larger sequence of values:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Grid of possible keepX values that will be tested for each comp}
\NormalTok{list.keepX }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\DecValTok{10}\NormalTok{,  }\FunctionTok{seq}\NormalTok{(}\DecValTok{20}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{10}\NormalTok{))}
\NormalTok{list.keepX}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This chunk takes \textasciitilde{} 2 min to run}
\CommentTok{\# Some convergence issues may arise but it is ok as this is run on CV folds}
\NormalTok{tune.splsda.srbct }\OtherTok{\textless{}{-}} \FunctionTok{tune.splsda}\NormalTok{(X, Y, }\AttributeTok{ncomp =} \DecValTok{4}\NormalTok{, }\AttributeTok{validation =} \StringTok{\textquotesingle{}Mfold\textquotesingle{}}\NormalTok{, }
                                 \AttributeTok{folds =} \DecValTok{5}\NormalTok{, }\AttributeTok{dist =} \StringTok{\textquotesingle{}max.dist\textquotesingle{}}\NormalTok{, }
                                 \AttributeTok{test.keepX =}\NormalTok{ list.keepX, }\AttributeTok{nrepeat =} \DecValTok{10}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The following command line will output the mean error rate for each component and each tested \texttt{keepX} value given the past (tuned) components.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Just a head of the classification error rate per keepX (in rows) and comp}
\FunctionTok{head}\NormalTok{(tune.splsda.srbct}\SpecialCharTok{$}\NormalTok{error.rate)}
\end{Highlighting}
\end{Shaded}

When we examine each individual row, this output globally shows that the classification error rate continues to decrease after the third component in sparse PLS-DA.

We display the mean classification error rate on each component, bearing in mind that each component is conditional on the previous components calculated with the optimal number of selected variables. The diamond in Figure \ref{fig:splsda-tune} indicates the best \texttt{keepX} value to achieve the lowest error rate per component.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# To show the error bars across the repeats:}
\FunctionTok{plot}\NormalTok{(tune.splsda.srbct, }\AttributeTok{sd =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



The tuning results depend on the tuning grid \texttt{list.keepX}, as well as the values chosen for \texttt{folds} and \texttt{nrepeat}. Therefore, we recommend assessing the performance of the \emph{final} model, as well as examining the stability of the selected variables across the different folds, as detailed in the next section.

Figure \ref{fig:splsda-tune} shows that the error rate decreases when more components are included in sPLS-DA. To obtain a more reliable estimation of the error rate, the number of repeats should be increased (between 50 to 100). This type of graph helps not only to choose the `optimal' number of variables to select, but also to confirm the number of components \texttt{ncomp}. From the code below, we can assess that in fact, the addition of a fourth component does not improve the classification (no statistically significant improvement according to a one-sided \(t-\)test), hence we can choose \texttt{ncomp\ =\ 3}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# The optimal number of components according to our one{-}sided t{-}tests}
\NormalTok{tune.splsda.srbct}\SpecialCharTok{$}\NormalTok{choice.ncomp}\SpecialCharTok{$}\NormalTok{ncomp}

\CommentTok{\# The optimal keepX parameter according to minimal error rate}
\NormalTok{tune.splsda.srbct}\SpecialCharTok{$}\NormalTok{choice.keepX}
\end{Highlighting}
\end{Shaded}

\hypertarget{final-splsda-perf}{%
\subsection{Final model and performance}\label{final-splsda-perf}}

Here is our final sPLS-DA model with three components and the optimal \texttt{keepX} obtained from our tuning step.

You can choose to skip the tuning step, and input your arbitrarily chosen parameters in the following code (simply specify your own \texttt{ncomp} and \texttt{keepX} values):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Optimal number of components based on t{-}tests on the error rate}
\NormalTok{ncomp }\OtherTok{\textless{}{-}}\NormalTok{ tune.splsda.srbct}\SpecialCharTok{$}\NormalTok{choice.ncomp}\SpecialCharTok{$}\NormalTok{ncomp }
\NormalTok{ncomp}

\CommentTok{\# Optimal number of variables to select}
\NormalTok{select.keepX }\OtherTok{\textless{}{-}}\NormalTok{ tune.splsda.srbct}\SpecialCharTok{$}\NormalTok{choice.keepX[}\DecValTok{1}\SpecialCharTok{:}\NormalTok{ncomp]  }
\NormalTok{select.keepX}

\NormalTok{splsda.srbct }\OtherTok{\textless{}{-}} \FunctionTok{splsda}\NormalTok{(X, Y, }\AttributeTok{ncomp =} \DecValTok{3}\NormalTok{, }\AttributeTok{keepX =}\NormalTok{ select.keepX) }
\end{Highlighting}
\end{Shaded}

The performance of the model with the \texttt{ncomp} and \texttt{keepX} parameters is assessed with the \texttt{perf()} function. We use 5-fold validation (\texttt{folds\ =\ 5}), repeated 10 times (\texttt{nrepeat\ =\ 10}) for illustrative purposes, but we recommend increasing to \texttt{nrepeat\ =\ 50}. Here we choose the \texttt{max.dist} prediction distance, based on our results obtained with PLS-DA.

The classification error rates that are output include both the overall error rate, as well as the balanced error rate (BER) when the number of samples per group is not balanced - as is the case in this study.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{34}\NormalTok{)  }\CommentTok{\# For reproducibility with this handbook, remove otherwise}

\NormalTok{perf.splsda.srbct }\OtherTok{\textless{}{-}} \FunctionTok{perf}\NormalTok{(splsda.srbct, }\AttributeTok{folds =} \DecValTok{5}\NormalTok{, }\AttributeTok{validation =} \StringTok{"Mfold"}\NormalTok{, }
                  \AttributeTok{dist =} \StringTok{"max.dist"}\NormalTok{, }\AttributeTok{progressBar =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{nrepeat =} \DecValTok{10}\NormalTok{)}

\CommentTok{\# perf.splsda.srbct  \# Lists the different outputs}
\NormalTok{perf.splsda.srbct}\SpecialCharTok{$}\NormalTok{error.rate}
\end{Highlighting}
\end{Shaded}

We can also examine the error rate per class:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{perf.splsda.srbct}\SpecialCharTok{$}\NormalTok{error.rate.class}
\end{Highlighting}
\end{Shaded}

These results can be compared with the performance of PLS-DA and show the benefits of variable selection to not only obtain a parsimonious model, but also to improve the classification error rate (overall and per class).

\hypertarget{plsda:stab}{%
\subsection{Variable selection and stability}\label{plsda:stab}}

During the repeated cross-validation process in \texttt{perf()} we can record how often the same variables are selected across the folds. This information is important to answer the question: \emph{How reproducible is my gene signature when the training set is perturbed via cross-validation?}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{))}
\CommentTok{\# For component 1}
\NormalTok{stable.comp1 }\OtherTok{\textless{}{-}}\NormalTok{ perf.splsda.srbct}\SpecialCharTok{$}\NormalTok{features}\SpecialCharTok{$}\NormalTok{stable}\SpecialCharTok{$}\NormalTok{comp1}
\FunctionTok{barplot}\NormalTok{(stable.comp1, }\AttributeTok{xlab =} \StringTok{\textquotesingle{}variables selected across CV folds\textquotesingle{}}\NormalTok{, }
        \AttributeTok{ylab =} \StringTok{\textquotesingle{}Stability frequency\textquotesingle{}}\NormalTok{,}
        \AttributeTok{main =} \StringTok{\textquotesingle{}Feature stability for comp = 1\textquotesingle{}}\NormalTok{)}

\CommentTok{\# For component 2}
\NormalTok{stable.comp2 }\OtherTok{\textless{}{-}}\NormalTok{ perf.splsda.srbct}\SpecialCharTok{$}\NormalTok{features}\SpecialCharTok{$}\NormalTok{stable}\SpecialCharTok{$}\NormalTok{comp2}
\FunctionTok{barplot}\NormalTok{(stable.comp2, }\AttributeTok{xlab =} \StringTok{\textquotesingle{}variables selected across CV folds\textquotesingle{}}\NormalTok{, }
        \AttributeTok{ylab =} \StringTok{\textquotesingle{}Stability frequency\textquotesingle{}}\NormalTok{,}
        \AttributeTok{main =} \StringTok{\textquotesingle{}Feature stability for comp = 2\textquotesingle{}}\NormalTok{)}
\FunctionTok{par}\NormalTok{(}\AttributeTok{mfrow=}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{))}
\end{Highlighting}
\end{Shaded}



Figure \ref{fig:splsda-stability} shows that the genes selected on component 1 are moderately stable (frequency \textless{} 0.5) whereas those selected on component 2 are more stable (frequency \textless{} 0.7). This can be explained as there are various combinations of genes that are discriminative on component 1, whereas the number of combinations decreases as we move to component 2 which attempts to refine the classification.

The function \texttt{selectVar()} outputs the variables selected for a given component and their loading values (ranked in decreasing absolute value). We concatenate those results with the feature stability, as shown here for variables selected on component 1:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# First extract the name of selected var:}
\NormalTok{select.name }\OtherTok{\textless{}{-}} \FunctionTok{selectVar}\NormalTok{(splsda.srbct, }\AttributeTok{comp =} \DecValTok{1}\NormalTok{)}\SpecialCharTok{$}\NormalTok{name}

\CommentTok{\# Then extract the stability values from perf:}
\NormalTok{stability }\OtherTok{\textless{}{-}}\NormalTok{ perf.splsda.srbct}\SpecialCharTok{$}\NormalTok{features}\SpecialCharTok{$}\NormalTok{stable}\SpecialCharTok{$}\NormalTok{comp1[select.name]}

\CommentTok{\# Just the head of the stability of the selected var:}
\FunctionTok{head}\NormalTok{(}\FunctionTok{cbind}\NormalTok{(}\FunctionTok{selectVar}\NormalTok{(splsda.srbct, }\AttributeTok{comp =} \DecValTok{1}\NormalTok{)}\SpecialCharTok{$}\NormalTok{value, stability))}
\end{Highlighting}
\end{Shaded}

As we hinted previously, the genes selected on the first component are not necessarily the most stable, suggesting that different combinations can lead to the same discriminative ability of the model. The stability increases in the following components, as the classification task becomes more refined.

Note:

\begin{itemize}
\tightlist
\item
  \emph{You can also apply the \texttt{vip()} function on \texttt{splsda.srbct}.}
\end{itemize}

\hypertarget{sample-visualisation}{%
\subsection{Sample visualisation}\label{sample-visualisation}}

Previously, we showed the ellipse plots displayed for each class. Here we also use the star argument (\texttt{star\ =\ TRUE}), which displays arrows starting from each group centroid towards each individual sample (Figure \ref{fig:splsda-indiv}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotIndiv}\NormalTok{(splsda.srbct, }\AttributeTok{comp =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{),}
          \AttributeTok{ind.names =} \ConstantTok{FALSE}\NormalTok{,}
          \AttributeTok{ellipse =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{,}
          \AttributeTok{star =} \ConstantTok{TRUE}\NormalTok{,}
          \AttributeTok{title =} \StringTok{\textquotesingle{}SRBCT, sPLS{-}DA comp 1 {-} 2\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotIndiv}\NormalTok{(splsda.srbct, }\AttributeTok{comp =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{),}
          \AttributeTok{ind.names =} \ConstantTok{FALSE}\NormalTok{,}
          \AttributeTok{ellipse =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{,}
          \AttributeTok{star =} \ConstantTok{TRUE}\NormalTok{,}
          \AttributeTok{title =} \StringTok{\textquotesingle{}SRBCT, sPLS{-}DA comp 2 {-} 3\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



The sample plots are different from PLS-DA (Figure \ref{fig:plsda-plotindiv}) with an overlap of specific classes (i.e.~\texttt{...colorize("grey",\ "NB")} + \texttt{...colorize("green",\ "RMS")} on component 1 and 2), that are then further separated on component 3, thus showing how the genes selected on each component discriminate particular sets of sample groups.

\hypertarget{plsda:varplot}{%
\subsection{Variable visualisation}\label{plsda:varplot}}

We represent the genes selected with sPLS-DA on the correlation circle plot. Here to increase interpretation, we specify the argument \texttt{var.names} as the first 10 characters of the gene names (Figure \ref{fig:splsda-var}). We also reduce the size of the font with the argument \texttt{cex}.

Note:

\begin{itemize}
\tightlist
\item
  \emph{We can store the \texttt{plotvar()} as an object to output the coordinates and variable names if the plot is too cluttered.}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{var.name.short }\OtherTok{\textless{}{-}} \FunctionTok{substr}\NormalTok{(srbct}\SpecialCharTok{$}\NormalTok{gene.name[, }\DecValTok{2}\NormalTok{], }\DecValTok{1}\NormalTok{, }\DecValTok{10}\NormalTok{)}
\FunctionTok{plotVar}\NormalTok{(splsda.srbct, }\AttributeTok{comp =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{), }
        \AttributeTok{var.names =} \FunctionTok{list}\NormalTok{(var.name.short), }\AttributeTok{cex =} \DecValTok{3}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



By considering both the correlation circle plot (Figure \ref{fig:splsda-var}) and the sample plot in Figure \ref{fig:splsda-indiv}, we observe that a group of genes with a positive correlation with component 1 (`EH domain', `proteasome' etc.) are associated with the \texttt{...colorize("orange",\ "BL")} samples. We also observe two groups of genes either positively or negatively correlated with component 2. These genes are likely to characterise either the \texttt{...colorize("grey",\ "NB")} + \texttt{...colorize("green",\ "RMS")} classes, or the \texttt{...colorize("blue",\ "EWS")} class. This interpretation can be further examined with the \texttt{plotLoadings()} function.

In this plot, the loading weights of each selected variable on each component are represented (see Module 2). The colours indicate the group in which the expression of the selected gene is maximal based on the mean (\texttt{method\ =\ \textquotesingle{}median\textquotesingle{}} is also available for skewed data). For example on component 1:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotLoadings}\NormalTok{(splsda.srbct, }\AttributeTok{comp =} \DecValTok{1}\NormalTok{, }\AttributeTok{method =} \StringTok{\textquotesingle{}mean\textquotesingle{}}\NormalTok{, }\AttributeTok{contrib =} \StringTok{\textquotesingle{}max\textquotesingle{}}\NormalTok{, }
             \AttributeTok{name.var =}\NormalTok{ var.name.short)}
\end{Highlighting}
\end{Shaded}



Here all genes are associated with \texttt{...colorize("orange",\ "BL")} (on average, their expression levels are higher in this class than in the other classes).

Notes:

\begin{itemize}
\tightlist
\item
  \emph{Consider using the argument \texttt{ndisplay} to only display the top selected genes if the signature is too large.}
\item
  \emph{Consider using the argument \texttt{contrib\ =\ \textquotesingle{}min\textquotesingle{}} to interpret the inverse trend of the signature (i.e.~which genes have the smallest expression in which class, here a mix of \texttt{...colorize("grey",\ "NB")} and \texttt{...colorize("green",\ "RMS")} samples).}
\end{itemize}

To complete the visualisation, the CIM in this special case is a simple hierarchical heatmap (see \texttt{?cim}) representing the expression levels of the genes selected across all three components with respect to each sample. Here we use an Euclidean distance with Complete agglomeration method, and we specify the argument \texttt{row.sideColors} to colour the samples according to their tumour type (Figure \ref{fig:splsda-cim}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cim}\NormalTok{(splsda.srbct, }\AttributeTok{row.sideColors =} \FunctionTok{color.mixo}\NormalTok{(Y))}
\end{Highlighting}
\end{Shaded}



The heatmap shows the level of expression of the genes selected by sPLS-DA across all three components, and the overall ability of the gene signature to discriminate the tumour subtypes.

Note:

\begin{itemize}
\tightlist
\item
  \emph{You can change the argument \texttt{comp} if you wish to visualise a specific set of components in \texttt{cim()}.}
\end{itemize}

\hypertarget{detour:plsda:predict}{%
\section{Take a detour: prediction}\label{detour:plsda:predict}}

In this section, we artificially create an `external' test set on which we want to predict the class membership to illustrate the prediction process in sPLS-DA (see Extra Reading material). We randomly select 50 samples from the \texttt{srbct} study as part of the training set, and the remainder as part of the test set:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{33}\NormalTok{) }\CommentTok{\# For reproducibility with this handbook, remove otherwise}
\NormalTok{train }\OtherTok{\textless{}{-}} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(X), }\DecValTok{50}\NormalTok{)    }\CommentTok{\# Randomly select 50 samples in training}
\NormalTok{test }\OtherTok{\textless{}{-}} \FunctionTok{setdiff}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(X), train) }\CommentTok{\# Rest is part of the test set}

\CommentTok{\# Store matrices into training and test set:}
\NormalTok{X.train }\OtherTok{\textless{}{-}}\NormalTok{ X[train, ]}
\NormalTok{X.test }\OtherTok{\textless{}{-}}\NormalTok{ X[test,]}
\NormalTok{Y.train }\OtherTok{\textless{}{-}}\NormalTok{ Y[train]}
\NormalTok{Y.test }\OtherTok{\textless{}{-}}\NormalTok{ Y[test]}

\CommentTok{\# Check dimensions are OK:}
\FunctionTok{dim}\NormalTok{(X.train); }\FunctionTok{dim}\NormalTok{(X.test)}
\end{Highlighting}
\end{Shaded}

Here we assume that the tuning step was performed on the training set \emph{only} (it is \emph{really important} to tune only on the training step to avoid overfitting), and that the optimal \texttt{keepX} values are, for example, \texttt{keepX\ =\ c(20,30,40)} on three components. The final model on the training data is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{train.splsda.srbct }\OtherTok{\textless{}{-}} \FunctionTok{splsda}\NormalTok{(X.train, Y.train, }\AttributeTok{ncomp =} \DecValTok{3}\NormalTok{, }\AttributeTok{keepX =} \FunctionTok{c}\NormalTok{(}\DecValTok{20}\NormalTok{,}\DecValTok{30}\NormalTok{,}\DecValTok{40}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

We now apply the trained model on the test set \texttt{X.test} and we specify the prediction distance, for example \texttt{mahalanobis.dist} (see also \texttt{?predict.splsda}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{predict.splsda.srbct }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(train.splsda.srbct, X.test, }
                                \AttributeTok{dist =} \StringTok{"mahalanobis.dist"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The \texttt{\$class} output of our object \texttt{predict.splsda.srbct} gives the predicted classes of the test samples.

First we concatenate the prediction for each of the three components (conditionally on the previous component) and the real class - in a real application case you may not know the true class.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Just the head:}
\FunctionTok{head}\NormalTok{(}\FunctionTok{data.frame}\NormalTok{(predict.splsda.srbct}\SpecialCharTok{$}\NormalTok{class, }\AttributeTok{Truth =}\NormalTok{ Y.test))}
\end{Highlighting}
\end{Shaded}

If we only look at the final prediction on component 2, compared to the real class:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compare prediction on the second component and change as factor}
\NormalTok{predict.comp2 }\OtherTok{\textless{}{-}}\NormalTok{ predict.splsda.srbct}\SpecialCharTok{$}\NormalTok{class}\SpecialCharTok{$}\NormalTok{mahalanobis.dist[,}\DecValTok{2}\NormalTok{]}
\FunctionTok{table}\NormalTok{(}\FunctionTok{factor}\NormalTok{(predict.comp2, }\AttributeTok{levels =} \FunctionTok{levels}\NormalTok{(Y)), Y.test)}
\end{Highlighting}
\end{Shaded}

And on the third compnent:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Compare prediction on the third component and change as factor}
\NormalTok{predict.comp3 }\OtherTok{\textless{}{-}}\NormalTok{ predict.splsda.srbct}\SpecialCharTok{$}\NormalTok{class}\SpecialCharTok{$}\NormalTok{mahalanobis.dist[,}\DecValTok{3}\NormalTok{]}
\FunctionTok{table}\NormalTok{(}\FunctionTok{factor}\NormalTok{(predict.comp3, }\AttributeTok{levels =} \FunctionTok{levels}\NormalTok{(Y)), Y.test)}
\end{Highlighting}
\end{Shaded}

The prediction is better on the third component, compared to a 2-component model.

Next, we look at the output \texttt{\$predict}, which gives the predicted dummy scores assigned for each test sample and each class level for a given component (as explained in Extra Reading material). Each column represents a class category:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# On component 3, just the head:}
\FunctionTok{head}\NormalTok{(predict.splsda.srbct}\SpecialCharTok{$}\NormalTok{predict[, , }\DecValTok{3}\NormalTok{])}
\end{Highlighting}
\end{Shaded}

In PLS-DA and sPLS-DA, the final prediction call is given based on this matrix on which a pre-specified distance (such as \texttt{mahalanobis.dist} here) is applied. From this output, we can understand the link between the dummy matrix \(\boldsymbol Y\), the prediction, and the importance of choosing the prediction distance. More details are provided in Extra Reading material.

\hypertarget{plsda:auroc}{%
\section{AUROC outputs complement performance evaluation}\label{plsda:auroc}}

As PLS-DA acts as a classifier, we can plot the AUC (Area Under The Curve) ROC (Receiver Operating Characteristics) to complement the sPLS-DA classification performance results. The AUC is calculated from training cross-validation sets and averaged. The ROC curve is displayed in Figure \ref{fig:splsda-roc}. In a multiclass setting, each curve represents one class vs.~the others and the AUC is indicated in the legend, and also in the numerical output:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{auc.srbct }\OtherTok{\textless{}{-}} \FunctionTok{auroc}\NormalTok{(splsda.srbct)}
\end{Highlighting}
\end{Shaded}



The ideal ROC curve should be along the top left corner, indicating a high true positive rate (sensitivity on the y-axis) and a high true negative rate (or low 100 - specificity on the x-axis), with an AUC close to 1. This is the case for \texttt{...colorize("darkred",\ "BL")} vs.~the others on component 1. The numerical output shows a perfect classification on component 3.

\emph{Note:}

\begin{itemize}
\tightlist
\item
  \emph{A word of caution when using the ROC and AUC in s/PLS-DA: these criteria may not be particularly insightful, or may not be in full agreement with the s/PLS-DA performance, as the prediction threshold in PLS-DA is based on a specified distance as we described earlier in this section and in Extra Reading material related to PLS-DA. Thus, such a result complements the sPLS-DA performance we have calculated earlier.}
\end{itemize}

\hypertarget{nInte}{%
\chapter{N-Integration}\label{nInte}}

\hypertarget{nInte:blockplsda-tcga-case}{%
\section{Block PLS-DA on the TCGA case study}\label{nInte:blockplsda-tcga-case}}

Human breast cancer is a heterogeneous disease in terms of molecular alterations, cellular composition, and clinical outcome. Breast tumours can be classified into several subtypes, according to their levels of mRNA expression \citep{Sor01}. Here we consider a subset of data generated by The Cancer Genome Atlas Network \citep{TCGA12}. For the package, data were normalised, and then drastically prefiltered for illustrative purposes.

The data were divided into a \emph{training set} with a subset of 150 samples from the mRNA, miRNA and proteomics data, and a \emph{test set} including 70 samples, but only with mRNA and miRNA data (the proteomics data are missing). The aim of this integrative analysis is to identify a highly correlated multi-omics signature discriminating the breast cancer subtypes Basal, Her2 and LumA.

The \texttt{breast.TCGA} (more details can be found in \texttt{?breast.TCGA}) is a list containing training and test sets of omics data \texttt{data.train} and \texttt{data.test} which include:

\begin{itemize}
\tightlist
\item
  \texttt{\$miRNA}: A data frame with 150 (70) rows and 184 columns in the training (test) data set for the miRNA expression levels,
\item
  \texttt{\$mRNA}: A data frame with 150 (70) rows and 520 columns in the training (test) data set for the mRNA expression levels,
\item
  \texttt{\$protein}: A data frame with 150 rows and 142 columns in the training data set for the protein abundance (there are no proteomics in the test set),
\item
  \texttt{\$subtype}: A factor indicating the breast cancer subtypes in the training (for 150 samples) and test sets (for 70 samples).
\end{itemize}

This case study covers an interesting scenario where one omic data set is missing in the test set, but because the method generates a set of components per training data set, we can still assess the prediction or performance evaluation using majority or weighted prediction vote.

\hypertarget{diablo:load}{%
\section{Load the data}\label{diablo:load}}

To illustrate the multiblock sPLS-DA approach, we will integrate the expression levels of miRNA, mRNA and the abundance of proteins while discriminating the subtypes of breast cancer, then predict the subtypes of the samples in the test set.

The input data is first set up as a list of \(Q\) matrices \(\boldsymbol X_1, \dots, \boldsymbol X_Q\) and a factor indicating the class membership of each sample \(\boldsymbol Y\). Each data frame in \(\boldsymbol X\) \emph{should be named} as we will match these names with the \texttt{keepX} parameter for the sparse method.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(mixOmics)}
\FunctionTok{data}\NormalTok{(breast.TCGA)}

\CommentTok{\# Extract training data and name each data frame}
\CommentTok{\# Store as list}
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{mRNA =}\NormalTok{ breast.TCGA}\SpecialCharTok{$}\NormalTok{data.train}\SpecialCharTok{$}\NormalTok{mrna, }
          \AttributeTok{miRNA =}\NormalTok{ breast.TCGA}\SpecialCharTok{$}\NormalTok{data.train}\SpecialCharTok{$}\NormalTok{mirna, }
          \AttributeTok{protein =}\NormalTok{ breast.TCGA}\SpecialCharTok{$}\NormalTok{data.train}\SpecialCharTok{$}\NormalTok{protein)}

\CommentTok{\# Outcome}
\NormalTok{Y }\OtherTok{\textless{}{-}}\NormalTok{ breast.TCGA}\SpecialCharTok{$}\NormalTok{data.train}\SpecialCharTok{$}\NormalTok{subtype}
\FunctionTok{summary}\NormalTok{(Y)}
\end{Highlighting}
\end{Shaded}

\hypertarget{parameter-choice}{%
\section{Parameter choice}\label{parameter-choice}}

\hypertarget{diablo:design}{%
\subsection{Design matrix}\label{diablo:design}}

The choice of the design can be motivated by different aspects, including:

\begin{itemize}
\item
  Biological apriori knowledge: Should we expect \texttt{mRNA} and \texttt{miRNA} to be highly correlated?
\item
  Analytical aims: As further developed in \citet{Sin19}, a compromise needs to be achieved between a classification and prediction task, and extracting the correlation structure of the data sets. A full design with weights = 1 will favour the latter, but at the expense of classification accuracy, whereas a design with small weights will lead to a highly predictive signature. This pertains to the complexity of the analytical task involved as several constraints are included in the optimisation procedure. For example, here we choose a 0.1 weighted model as we are interested in predicting test samples later in this case study.
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{design }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FloatTok{0.1}\NormalTok{, }\AttributeTok{ncol =} \FunctionTok{length}\NormalTok{(X), }\AttributeTok{nrow =} \FunctionTok{length}\NormalTok{(X), }
                \AttributeTok{dimnames =} \FunctionTok{list}\NormalTok{(}\FunctionTok{names}\NormalTok{(X), }\FunctionTok{names}\NormalTok{(X)))}
\FunctionTok{diag}\NormalTok{(design) }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{design }
\end{Highlighting}
\end{Shaded}

Note however that even with this design, we will still unravel a correlated signature as we require all data sets to explain the same outcome \(\boldsymbol y\), as well as maximising pairs of covariances between data sets.

\begin{itemize}
\tightlist
\item
  Data-driven option: we could perform regression analyses with PLS to further understand the correlation between data sets. Here for example, we run PLS with one component and calculate the cross-correlations between components associated to each data set:
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{res1.pls.tcga }\OtherTok{\textless{}{-}} \FunctionTok{pls}\NormalTok{(X}\SpecialCharTok{$}\NormalTok{mRNA, X}\SpecialCharTok{$}\NormalTok{protein, }\AttributeTok{ncomp =} \DecValTok{1}\NormalTok{)}
\FunctionTok{cor}\NormalTok{(res1.pls.tcga}\SpecialCharTok{$}\NormalTok{variates}\SpecialCharTok{$}\NormalTok{X, res1.pls.tcga}\SpecialCharTok{$}\NormalTok{variates}\SpecialCharTok{$}\NormalTok{Y)}

\NormalTok{res2.pls.tcga }\OtherTok{\textless{}{-}} \FunctionTok{pls}\NormalTok{(X}\SpecialCharTok{$}\NormalTok{mRNA, X}\SpecialCharTok{$}\NormalTok{miRNA, }\AttributeTok{ncomp =} \DecValTok{1}\NormalTok{)}
\FunctionTok{cor}\NormalTok{(res2.pls.tcga}\SpecialCharTok{$}\NormalTok{variates}\SpecialCharTok{$}\NormalTok{X, res2.pls.tcga}\SpecialCharTok{$}\NormalTok{variates}\SpecialCharTok{$}\NormalTok{Y)}

\NormalTok{res3.pls.tcga }\OtherTok{\textless{}{-}} \FunctionTok{pls}\NormalTok{(X}\SpecialCharTok{$}\NormalTok{protein, X}\SpecialCharTok{$}\NormalTok{miRNA, }\AttributeTok{ncomp =} \DecValTok{1}\NormalTok{)}
\FunctionTok{cor}\NormalTok{(res3.pls.tcga}\SpecialCharTok{$}\NormalTok{variates}\SpecialCharTok{$}\NormalTok{X, res3.pls.tcga}\SpecialCharTok{$}\NormalTok{variates}\SpecialCharTok{$}\NormalTok{Y)}
\end{Highlighting}
\end{Shaded}

The data sets taken in a pairwise manner are highly correlated, indicating that a design with weights \(\sim 0.8 - 0.9\) could be chosen.

\hypertarget{number-of-components}{%
\subsection{Number of components}\label{number-of-components}}

As in the PLS-DA framework presented in Module 3, we first fit a \texttt{block.plsda} model without variable selection to assess the global performance of the model and choose the number of components. We run \texttt{perf()} with 10-fold cross validation repeated 10 times for up to 5 components and with our specified design matrix. Similar to PLS-DA, we obtain the performance of the model with respect to the different prediction distances (Figure \ref{fig:diablo-perf}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diablo.tcga }\OtherTok{\textless{}{-}} \FunctionTok{block.plsda}\NormalTok{(X, Y, }\AttributeTok{ncomp =} \DecValTok{5}\NormalTok{, }\AttributeTok{design =}\NormalTok{ design)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{) }\CommentTok{\# For reproducibility, remove for your analyses}
\NormalTok{perf.diablo.tcga }\OtherTok{=} \FunctionTok{perf}\NormalTok{(diablo.tcga, }\AttributeTok{validation =} \StringTok{\textquotesingle{}Mfold\textquotesingle{}}\NormalTok{, }\AttributeTok{folds =} \DecValTok{10}\NormalTok{, }\AttributeTok{nrepeat =} \DecValTok{10}\NormalTok{)}

\CommentTok{\#perf.diablo.tcga$error.rate  \# Lists the different types of error rates}

\CommentTok{\# Plot of the error rates based on weighted vote}
\FunctionTok{plot}\NormalTok{(perf.diablo.tcga)}
\end{Highlighting}
\end{Shaded}



The performance plot indicates that two components should be sufficient in the final model, and that the centroids distance might lead to better prediction. A balanced error rate (BER) should be considered for further analysis.

The following outputs the optimal number of components according to the prediction distance and type of error rate (overall or balanced), as well as a prediction weighting scheme illustrated further below.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{perf.diablo.tcga}\SpecialCharTok{$}\NormalTok{choice.ncomp}\SpecialCharTok{$}\NormalTok{WeightedVote}
\end{Highlighting}
\end{Shaded}

Thus, here we choose our final \texttt{ncomp} value:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ncomp }\OtherTok{\textless{}{-}}\NormalTok{ perf.diablo.tcga}\SpecialCharTok{$}\NormalTok{choice.ncomp}\SpecialCharTok{$}\NormalTok{WeightedVote[}\StringTok{"Overall.BER"}\NormalTok{, }\StringTok{"centroids.dist"}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\hypertarget{diablo:numvar}{%
\subsection{Number of variables to select}\label{diablo:numvar}}

We then choose the optimal number of variables to select in each data set using the \texttt{tune.block.splsda} function. The function \texttt{tune()} is run with 10-fold cross validation, but repeated only once (\texttt{nrepeat\ =\ 1}) for illustrative and computational reasons here. For a thorough tuning process, we advise increasing the \texttt{nrepeat} argument to 10-50, or more.

We choose a \texttt{keepX} grid that is relatively fine at the start, then coarse. If the data sets are easy to classify, the tuning step may indicate the smallest number of variables to separate the sample groups. Hence, we start our grid at the value \texttt{5} to avoid a too small signature that may preclude biological interpretation.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# This code may take several min to run, parallelisation is possible}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{) }\CommentTok{\# For reproducibility with this handbook, remove otherwise}
\NormalTok{test.keepX }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{mRNA =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\SpecialCharTok{:}\DecValTok{9}\NormalTok{, }\FunctionTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{5}\NormalTok{)),}
                   \AttributeTok{miRNA =} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\SpecialCharTok{:}\DecValTok{9}\NormalTok{, }\FunctionTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{20}\NormalTok{, }\DecValTok{2}\NormalTok{)),}
                   \AttributeTok{proteomics =} \FunctionTok{c}\NormalTok{(}\FunctionTok{seq}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{25}\NormalTok{, }\DecValTok{5}\NormalTok{)))}

\NormalTok{tune.diablo.tcga }\OtherTok{\textless{}{-}} \FunctionTok{tune.block.splsda}\NormalTok{(X, Y, }\AttributeTok{ncomp =} \DecValTok{2}\NormalTok{, }
                              \AttributeTok{test.keepX =}\NormalTok{ test.keepX, }\AttributeTok{design =}\NormalTok{ design,}
                              \AttributeTok{validation =} \StringTok{\textquotesingle{}Mfold\textquotesingle{}}\NormalTok{, }\AttributeTok{folds =} \DecValTok{10}\NormalTok{, }\AttributeTok{nrepeat =} \DecValTok{1}\NormalTok{, }
                              \AttributeTok{dist =} \StringTok{"centroids.dist"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Note:

\begin{itemize}
\tightlist
\item
  \emph{For fast computation, we can use parallel computing here - this option is also enabled on a laptop or workstation, see \texttt{?tune.block.splsda}.}
\end{itemize}

The number of features to select on each component is returned and stored for the final model:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{list.keepX }\OtherTok{\textless{}{-}}\NormalTok{ tune.diablo.tcga}\SpecialCharTok{$}\NormalTok{choice.keepX}
\NormalTok{list.keepX}
\end{Highlighting}
\end{Shaded}

Note:

\begin{itemize}
\tightlist
\item
  \emph{You can skip any of the tuning steps above, and hard code your chosen \texttt{ncomp} and \texttt{keepX} parameters (as a list for the latter, as shown below).}
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{list.keepX }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{( }\AttributeTok{mRNA =} \FunctionTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{, }\DecValTok{25}\NormalTok{), }\AttributeTok{miRNA =} \FunctionTok{c}\NormalTok{(}\DecValTok{14}\NormalTok{,}\DecValTok{5}\NormalTok{), }\AttributeTok{protein =} \FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{, }\DecValTok{5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\hypertarget{final-model}{%
\section{Final model}\label{final-model}}

The final multiblock sPLS-DA model includes the tuned parameters and is run as:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diablo.tcga }\OtherTok{\textless{}{-}} \FunctionTok{block.splsda}\NormalTok{(X, Y, }\AttributeTok{ncomp =}\NormalTok{ ncomp, }
                            \AttributeTok{keepX =}\NormalTok{ list.keepX, }\AttributeTok{design =}\NormalTok{ design)}
\CommentTok{\#diablo.tcga   \# Lists the different functions of interest related to that object}
\end{Highlighting}
\end{Shaded}

A warning message informs us that the outcome \(\boldsymbol Y\) has been included automatically in the design, so that the covariance between each block's component and the outcome is maximised, as shown in the final design output:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{diablo.tcga}\SpecialCharTok{$}\NormalTok{design}
\end{Highlighting}
\end{Shaded}

The selected variables can be extracted with the function \texttt{selectVar()}, for example in the mRNA block, along with their loading weights (not output here):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# mRNA variables selected on component 1}
\FunctionTok{selectVar}\NormalTok{(diablo.tcga, }\AttributeTok{block =} \StringTok{\textquotesingle{}mRNA\textquotesingle{}}\NormalTok{, }\AttributeTok{comp =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\emph{Note:}

\begin{itemize}
\tightlist
\item
  \emph{The stability of the selected variables can be extracted from the \texttt{perf()} function, similar to the example given in the PLS-DA analysis (Module 3).}
\end{itemize}

\hypertarget{diablo:result:sampleplot}{%
\section{Sample plots}\label{diablo:result:sampleplot}}

\hypertarget{plotdiablo}{%
\subsection{\texorpdfstring{\texttt{plotDiablo}}{plotDiablo}}\label{plotdiablo}}

\texttt{plotDiablo()} is a diagnostic plot to check whether the correlations between components from each data set were maximised as specified in the design matrix. We specify the dimension to be assessed with the \texttt{ncomp} argument (Figure \ref{fig:plot-diablo}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotDiablo}\NormalTok{(diablo.tcga, }\AttributeTok{ncomp =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



The plot indicates that the first components from all data sets are highly correlated. The colours and ellipses represent the sample subtypes and indicate the discriminative power of each component to separate the different tumour subtypes. Thus, multiblock sPLS-DA is able to extract a strong correlation structure between data sets, as well as discriminate the breast cancer subtypes on the first component.

\hypertarget{plotindiv}{%
\subsection{\texorpdfstring{\texttt{plotIndiv}}{plotIndiv}}\label{plotindiv}}

The sample plot with the \texttt{plotIndiv()} function projects each sample into the space spanned by the components from \emph{each} block, resulting in a series of graphs corresponding to each data set (Figure \ref{fig:diablo-plotindiv}). The optional argument \texttt{blocks} can output a specific data set. Ellipse plots are also available (argument \texttt{ellipse\ =\ TRUE}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotIndiv}\NormalTok{(diablo.tcga, }\AttributeTok{ind.names =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{, }
          \AttributeTok{title =} \StringTok{\textquotesingle{}TCGA, DIABLO comp 1 {-} 2\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



This type of graphic allows us to better understand the information extracted from each data set and its discriminative ability. Here we can see that the \texttt{...colorize("grey",\ "LumA")} group can be difficult to classify in the miRNA data.

Note:

\begin{itemize}
\tightlist
\item
  \emph{Additional variants include the argument \texttt{block\ =\ \textquotesingle{}average\textquotesingle{}} that averages the components from all blocks to produce a single plot. The argument \texttt{block=\textquotesingle{}weighted.average\textquotesingle{}} is a weighted average of the components according to their correlation with the components associated with the outcome}.
\end{itemize}

\hypertarget{plotarrow}{%
\subsection{\texorpdfstring{\texttt{plotArrow}}{plotArrow}}\label{plotarrow}}

In the arrow plot in Figure \ref{fig:diablo-plotarrow}, the start of the arrow indicates the centroid between all data sets for a given sample and the tip of the arrow the location of that same sample but in each block. Such graphics highlight the agreement between all data sets at the sample level when modelled with multiblock sPLS-DA.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotArrow}\NormalTok{(diablo.tcga, }\AttributeTok{ind.names =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{, }
          \AttributeTok{title =} \StringTok{\textquotesingle{}TCGA, DIABLO comp 1 {-} 2\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



This plot shows that globally, the discrimination of all breast cancer subtypes can be extracted from all data sets, however, there are some dissimilarities at the samples level across data sets (the common information cannot be extracted in the same way across data sets).

\hypertarget{diablo:result:varplot}{%
\section{Variable plots}\label{diablo:result:varplot}}

The visualisation of the selected variables is crucial to mine their associations in multiblock sPLS-DA. Here we revisit existing outputs presented in Module 2 with further developments for multiple data set integration. All the plots presented provide complementary information for interpreting the results.

\hypertarget{plotvar}{%
\subsection{\texorpdfstring{\texttt{plotVar}}{plotVar}}\label{plotvar}}

The correlation circle plot highlights the contribution of each selected variable to each component. Important variables should be close to the large circle (see Module 2). Here, only the variables selected on components 1 and 2 are depicted (across all blocks), see Figure \ref{fig:diablo-plotvar}. Clusters of points indicate a strong correlation between variables. For better visibility we chose to hide the variable names.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotVar}\NormalTok{(diablo.tcga, }\AttributeTok{var.names =} \ConstantTok{FALSE}\NormalTok{, }\AttributeTok{style =} \StringTok{\textquotesingle{}graphics\textquotesingle{}}\NormalTok{, }\AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{, }
        \AttributeTok{pch =} \FunctionTok{c}\NormalTok{(}\DecValTok{16}\NormalTok{, }\DecValTok{17}\NormalTok{, }\DecValTok{15}\NormalTok{), }\AttributeTok{cex =} \FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{), }
        \AttributeTok{col =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}darkorchid\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}brown1\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}lightgreen\textquotesingle{}}\NormalTok{),}
        \AttributeTok{title =} \StringTok{\textquotesingle{}TCGA, DIABLO comp 1 {-} 2\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



The correlation circle plot shows some positive correlations (between selected \texttt{...colorize("brown",\ "miRNA")} and \texttt{...colorize("lightgreen",\ "proteins")}, between selected \texttt{...colorize("lightgreen",\ "proteins")} and \texttt{...colorize("darkorchid",\ "mRNA")}) and negative correlations between \texttt{...colorize("darkorchid",\ "mRNA")}and \texttt{...colorize("brown",\ "miRNA")} on component 1. The correlation structure is less obvious on component 2, but we observe some key selected features (\texttt{...colorize("lightgreen",\ "proteins")} and \texttt{...colorize("brown",\ "miRNA")}) that seem to highly contribute to component 2.

Note:

\begin{itemize}
\item
  \emph{These results can be further investigated by showing the variable names on this plot (or extracting their coordinates available from the plot saved into an object, see \texttt{?plotVar}), and looking at various outputs from \texttt{selectVar()} and \texttt{plotLoadings()}.}
\item
  \emph{You can choose to only show specific variable type names, e.g.~\texttt{var.names\ =\ c(FALSE,\ FALSE,\ TRUE)} (where each argument is assigned to a data set in \(\boldsymbol X\)). Here for example, the protein names only would be output.}
\end{itemize}

\hypertarget{circosplot}{%
\subsection{\texorpdfstring{\texttt{circosPlot}}{circosPlot}}\label{circosplot}}

The circos plot represents the correlations between variables of different types, represented on the side quadrants. Several display options are possible, to show within and between connections between blocks, and expression levels of each variable according to each class (argument \texttt{line\ =\ TRUE}). The circos plot is built based on a similarity matrix, which was extended to the case of multiple data sets from \citet{Gon12} (see also Module 2 and Extra Reading material from that module). A \texttt{cutoff} argument can be further included to visualise correlation coefficients above this threshold in the multi-omics signature (Figure \ref{fig:diablo-circos}). The colours for the blocks and correlation lines can be chosen with \texttt{color.blocks} and \texttt{color.cor} respectively:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{circosPlot}\NormalTok{(diablo.tcga, }\AttributeTok{cutoff =} \FloatTok{0.7}\NormalTok{, }\AttributeTok{line =} \ConstantTok{TRUE}\NormalTok{, }
           \AttributeTok{color.blocks =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}darkorchid\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}brown1\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}lightgreen\textquotesingle{}}\NormalTok{),}
           \AttributeTok{color.cor =} \FunctionTok{c}\NormalTok{(}\StringTok{"chocolate3"}\NormalTok{,}\StringTok{"grey20"}\NormalTok{), }\AttributeTok{size.labels =} \FloatTok{1.5}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



The circos plot enables us to visualise cross-correlations between data types, and the nature of these correlations (\texttt{...colorize("brown",\ "positive")} or negative). Here we observe that correlations \textgreater{} 0.7 are between a few \texttt{...colorize("darkorchid",\ "mRNA")}and some \texttt{...colorize("green",\ "Proteins")}, whereas the majority of strong (negative) correlations are observed between \texttt{...colorize("darkred",\ "miRNA")} and \texttt{...colorize("darkorchid",\ "mRNA")}or \texttt{...colorize("green",\ "Proteins")}. The lines indicating the average expression levels per breast cancer subtype indicate that the selected features are able to discriminate the sample groups.

\hypertarget{network}{%
\subsection{\texorpdfstring{\texttt{network}}{network}}\label{network}}

Relevance networks, which are also built on the similarity matrix, can also visualise the correlations between the different types of variables. Each colour represents a type of variable. A threshold can also be set using the argument \texttt{cutoff} (Figure \ref{fig:diablo-network}). By default the network includes only variables selected on component 1, unless specified in \texttt{comp}.

Note that sometimes the output may not show with Rstudio due to margin issues. We can either use \texttt{X11()} to open a new window, or save the plot as an image using the arguments \texttt{save} and \texttt{name.save}, as we show below. An \texttt{interactive} argument is also available for the \texttt{cutoff} argument, see details in \texttt{?network}.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# X11()   \# Opens a new window}
\FunctionTok{network}\NormalTok{(diablo.tcga, }\AttributeTok{blocks =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }
        \AttributeTok{cutoff =} \FloatTok{0.4}\NormalTok{,}
        \AttributeTok{color.node =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}darkorchid\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}brown1\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}lightgreen\textquotesingle{}}\NormalTok{),}
        \CommentTok{\# To save the plot, comment out otherwise}
        \AttributeTok{save =} \StringTok{\textquotesingle{}png\textquotesingle{}}\NormalTok{, }\AttributeTok{name.save =} \StringTok{\textquotesingle{}diablo{-}network\textquotesingle{}}
\NormalTok{        )}
\end{Highlighting}
\end{Shaded}



The relevance network in Figure \ref{fig:diablo-network} shows two groups of features of different types. Within each group we observe positive and negative correlations. The visualisation of this plot could be further improved by changing the names of the original features.

Note that the network can be saved in a .gml format to be input into the software Cytoscape, using the R package \texttt{igraph} \citep{csa06}:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Not run}
\FunctionTok{library}\NormalTok{(igraph)}
\NormalTok{myNetwork }\OtherTok{\textless{}{-}} \FunctionTok{network}\NormalTok{(diablo.tcga, }\AttributeTok{blocks =} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{), }\AttributeTok{cutoff =} \FloatTok{0.4}\NormalTok{)}
\FunctionTok{write.graph}\NormalTok{(myNetwork}\SpecialCharTok{$}\NormalTok{gR, }\AttributeTok{file =} \StringTok{"myNetwork.gml"}\NormalTok{, }\AttributeTok{format =} \StringTok{"gml"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{plotloadings}{%
\subsection{\texorpdfstring{\texttt{plotLoadings}}{plotLoadings}}\label{plotloadings}}

\texttt{plotLoadings()} visualises the loading weights of each selected variable on each component and each data set. The colour indicates the class in which the variable has the maximum level of expression (\texttt{contrib\ =\ \textquotesingle{}max\textquotesingle{}}) or minimum (\texttt{contrib\ =\ \textquotesingle{}min\textquotesingle{}}), on average (\texttt{method\ =\ \textquotesingle{}mean\textquotesingle{}}) or using the median (\texttt{method\ =\ \textquotesingle{}median\textquotesingle{}}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotLoadings}\NormalTok{(diablo.tcga, }\AttributeTok{comp =} \DecValTok{1}\NormalTok{, }\AttributeTok{contrib =} \StringTok{\textquotesingle{}max\textquotesingle{}}\NormalTok{, }\AttributeTok{method =} \StringTok{\textquotesingle{}median\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



The loading plot shows the multi-omics signature selected on component 1, where each panel represents one data type. The importance of each variable is visualised by the length of the bar (i.e.~its loading coefficient value). The combination of the sign of the coefficient (positive / negative) and the colours indicate that component 1 discriminates primarily the \texttt{...colorize("blue",\ "Basal")} samples vs.~the \texttt{...colorize("grey",\ "LumA")} samples (see the sample plots also). The features selected are highly expressed in one of these two subtypes. One could also plot the second component that discriminates the \texttt{...colorize("orange",\ "Her2")} samples.

\hypertarget{cimdiablo}{%
\subsection{\texorpdfstring{\texttt{cimDiablo}}{cimDiablo}}\label{cimdiablo}}

The \texttt{cimDiablo()} function is a clustered image map specifically implemented to represent the multi-omics molecular signature expression for each sample. It is very similar to a classical hierarchical clustering (Figure \ref{fig:diablo-cim}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{cimDiablo}\NormalTok{(diablo.tcga, }\AttributeTok{color.blocks =} \FunctionTok{c}\NormalTok{(}\StringTok{\textquotesingle{}darkorchid\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}brown1\textquotesingle{}}\NormalTok{, }\StringTok{\textquotesingle{}lightgreen\textquotesingle{}}\NormalTok{),}
          \AttributeTok{comp =} \DecValTok{1}\NormalTok{, }\AttributeTok{margin=}\FunctionTok{c}\NormalTok{(}\DecValTok{8}\NormalTok{,}\DecValTok{20}\NormalTok{), }\AttributeTok{legend.position =} \StringTok{"right"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



According to the CIM, component 1 seems to primarily classify the \texttt{...colorize("blue",\ "Basal")} samples, with a group of overexpressed \texttt{...colorize("brown",\ "miRNA")} and underexpressed \texttt{...colorize("darkorchid",\ "mRNA")}and \texttt{...colorize("lightgreen",\ "proteins")}. A group of \texttt{...colorize("grey",\ "LumA")} samples can also be identified due to the overexpression of the same \texttt{...colorize("darkorchid",\ "mRNA")}and \texttt{...colorize("lightgreen",\ "proteins")}. \texttt{...colorize("orange",\ "Her2")} samples remain quite mixed with the other \texttt{...colorize("grey",\ "LumA")} samples.

\hypertarget{diablo:perf}{%
\section{Model performance and prediction}\label{diablo:perf}}

We assess the performance of the model using 10-fold cross-validation repeated 10 times with the function \texttt{perf()}. The method runs a \texttt{block.splsda()} model on the pre-specified arguments input from our final object \texttt{diablo.tcga} but on cross-validated samples. We then assess the accuracy of the prediction on the left out samples. Since the \texttt{tune()} function was used with the \texttt{centroid.dist} argument, we examine the outputs of the \texttt{perf()} function for that same distance:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{) }\CommentTok{\# For reproducibility with this handbook, remove otherwise}
\NormalTok{perf.diablo.tcga }\OtherTok{\textless{}{-}} \FunctionTok{perf}\NormalTok{(diablo.tcga,  }\AttributeTok{validation =} \StringTok{\textquotesingle{}Mfold\textquotesingle{}}\NormalTok{, }\AttributeTok{folds =} \DecValTok{10}\NormalTok{, }
                         \AttributeTok{nrepeat =} \DecValTok{10}\NormalTok{, }\AttributeTok{dist =} \StringTok{\textquotesingle{}centroids.dist\textquotesingle{}}\NormalTok{)}

\CommentTok{\#perf.diablo.tcga  \# Lists the different outputs}
\end{Highlighting}
\end{Shaded}

We can extract the (balanced) classification error rates globally or overall with
\texttt{perf.diablo.tcga\$error.rate.per.class}, the predicted components associated to \(\boldsymbol Y\), or the stability of the selected features with \texttt{perf.diablo.tcga\$features}.

Here we look at the different performance assessment schemes specific to multiple data set integration.

First, we output the performance with the majority vote, that is, since the prediction is based on the components associated to their own data set, we can then weight those predictions across data sets according to a majority vote scheme. Based on the predicted classes, we then extract the classification error rate per class and per component:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Performance with Majority vote}
\NormalTok{perf.diablo.tcga}\SpecialCharTok{$}\NormalTok{MajorityVote.error.rate}
\end{Highlighting}
\end{Shaded}

The output shows that with the exception of the Basal samples, the classification improves with the addition of the second component.

Another prediction scheme is to weight the classification error rate from each data set according to the correlation between the predicted components and the \(\boldsymbol Y\) outcome.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Performance with Weighted vote}
\NormalTok{perf.diablo.tcga}\SpecialCharTok{$}\NormalTok{WeightedVote.error.rate}
\end{Highlighting}
\end{Shaded}

Compared to the previous majority vote output, we can see that the classification accuracy is slightly better on component 2 for the subtype Her2.

An AUC plot \emph{per block} is plotted using the function \texttt{auroc()}. We have already mentioned in Module 3 for PLS-DA, the interpretation of this output may not be particularly insightful in relation to the performance evaluation of our methods, but can complement the statistical analysis. For example, here for the miRNA data set once we have reached component 2 (Figure \ref{fig:diablo-auroc}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{auc.diablo.tcga }\OtherTok{\textless{}{-}} \FunctionTok{auroc}\NormalTok{(diablo.tcga, }\AttributeTok{roc.block =} \StringTok{"miRNA"}\NormalTok{, }\AttributeTok{roc.comp =} \DecValTok{2}\NormalTok{,}
                   \AttributeTok{print =} \ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



Figure \ref{fig:diablo-auroc} shows that the Her2 subtype is the most difficult to classify with multiblock sPLS-DA compared to the other subtypes.

The \texttt{predict()} function associated with a \texttt{block.splsda()} object predicts the class of samples from an external test set. In our specific case, one data set is missing in the test set but the method can still be applied. We need to ensure the names of the blocks correspond exactly to those from the training set:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Prepare test set data: here one block (proteins) is missing}
\NormalTok{data.test.tcga }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{(}\AttributeTok{mRNA =}\NormalTok{ breast.TCGA}\SpecialCharTok{$}\NormalTok{data.test}\SpecialCharTok{$}\NormalTok{mrna, }
                      \AttributeTok{miRNA =}\NormalTok{ breast.TCGA}\SpecialCharTok{$}\NormalTok{data.test}\SpecialCharTok{$}\NormalTok{mirna)}

\NormalTok{predict.diablo.tcga }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(diablo.tcga, }\AttributeTok{newdata =}\NormalTok{ data.test.tcga)}
\CommentTok{\# The warning message will inform us that one block is missing}

\CommentTok{\#predict.diablo \# List the different outputs}
\end{Highlighting}
\end{Shaded}

The following output is a confusion matrix that compares the real subtypes with the predicted subtypes for a 2 component model, for the distance of interest \texttt{centroids.dist} and the prediction scheme \texttt{WeightedVote}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{confusion.mat.tcga }\OtherTok{\textless{}{-}} \FunctionTok{get.confusion\_matrix}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ breast.TCGA}\SpecialCharTok{$}\NormalTok{data.test}\SpecialCharTok{$}\NormalTok{subtype, }
                     \AttributeTok{predicted =}\NormalTok{ predict.diablo.tcga}\SpecialCharTok{$}\NormalTok{WeightedVote}\SpecialCharTok{$}\NormalTok{centroids.dist[,}\DecValTok{2}\NormalTok{])}
\NormalTok{confusion.mat.tcga}
\end{Highlighting}
\end{Shaded}

From this table, we see that one Basal and one Her2 sample are wrongly predicted as Her2 and Lum A respectively, and 3 LumA samples are wrongly predicted as Her2. The balanced prediction error rate can be obtained as:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{get.BER}\NormalTok{(confusion.mat.tcga)}
\end{Highlighting}
\end{Shaded}

It would be worthwhile at this stage to revisit the chosen design of the multiblock sPLS-DA model to assess the influence of the design on the prediction performance on this test set - even though this back and forth analysis is a biased criterion to choose the design!

\hypertarget{pInte}{%
\chapter{P-Integration}\label{pInte}}

\hypertarget{pInte:mint-stemcell-case}{%
\section{MINT on the stem cell case study}\label{pInte:mint-stemcell-case}}

We integrate four transcriptomics studies of microarray stem cells (125 samples in total). The original data set from the Stemformatics database\footnote{www.stemformatics.org} \citep{Well13} was reduced to fit into the package, and includes a randomly-chosen subset of the expression levels of 400 genes. The aim is to classify three types of human cells: human fibroblasts (Fib) and human induced Pluripotent Stem Cells (hiPSC \& hESC).

There is a biological hierarchy among the three cell types. On one hand, differences between pluripotent (hiPSC and hESC) and non-pluripotent cells (Fib) are well-characterised and are expected to contribute to the main biological variation. On the other hand, hiPSC are genetically reprogrammed to behave like hESC and both cell types are commonly assumed to be alike. However, differences have been reported in the literature (\citet{Chi09}, \citet{New10}). We illustrate the use of MINT to address sub-classification problems in a single analysis.

\hypertarget{mint:load}{%
\section{Load the data}\label{mint:load}}

We first load the data from the package and set up the categorical outcome \(\boldsymbol Y\) and the \texttt{study} membership:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(mixOmics)}
\FunctionTok{data}\NormalTok{(stemcells)}

\CommentTok{\# The combined data set X}
\NormalTok{X }\OtherTok{\textless{}{-}}\NormalTok{ stemcells}\SpecialCharTok{$}\NormalTok{gene}
\FunctionTok{dim}\NormalTok{(X)}

\CommentTok{\# The outcome vector Y:  }
\NormalTok{Y }\OtherTok{\textless{}{-}}\NormalTok{ stemcells}\SpecialCharTok{$}\NormalTok{celltype }
\FunctionTok{length}\NormalTok{(Y) }

\FunctionTok{summary}\NormalTok{(Y)}
\end{Highlighting}
\end{Shaded}

We then store the vector indicating the sample membership of each independent study:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{study }\OtherTok{\textless{}{-}}\NormalTok{ stemcells}\SpecialCharTok{$}\NormalTok{study}

\CommentTok{\# Number of samples per study:}
\FunctionTok{summary}\NormalTok{(study)}

\CommentTok{\# Experimental design}
\FunctionTok{table}\NormalTok{(Y,study)}
\end{Highlighting}
\end{Shaded}

\hypertarget{mint:plsda}{%
\section{Example: MINT PLS-DA}\label{mint:plsda}}

We first perform a MINT PLS-DA with all variables included in the model and \texttt{ncomp\ =\ 5} components. The \texttt{perf()} function is used to estimate the performance of the model using LOGOCV, and to choose the optimal number of components for our final model (see Fig \ref{fig:MINT-perf}).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{mint.plsda.stem }\OtherTok{\textless{}{-}} \FunctionTok{mint.plsda}\NormalTok{(}\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{Y =}\NormalTok{ Y, }\AttributeTok{study =}\NormalTok{ study, }\AttributeTok{ncomp =} \DecValTok{5}\NormalTok{)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2543}\NormalTok{) }\CommentTok{\# For reproducible results here, remove for your own analyses}
\NormalTok{perf.mint.plsda.stem }\OtherTok{\textless{}{-}} \FunctionTok{perf}\NormalTok{(mint.plsda.stem) }

\FunctionTok{plot}\NormalTok{(perf.mint.plsda.stem)}
\end{Highlighting}
\end{Shaded}



Based on the performance plot (Figure \ref{fig:MINT-perf}), \texttt{ncomp\ =\ 2} seems to achieve the best performance for the centroid distance, and \texttt{ncomp\ =\ 1} for the Mahalanobis distance in terms of BER. Additional numerical outputs such as the BER and overall error rates per component, and the error rates per class and per prediction distance, can be output:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{perf.mint.plsda.stem}\SpecialCharTok{$}\NormalTok{global.error}\SpecialCharTok{$}\NormalTok{BER}
\CommentTok{\# Type also:}
\CommentTok{\# perf.mint.plsda.stem$global.error}
\end{Highlighting}
\end{Shaded}

While we may want to focus our interpretation on the first component, we run a final MINT PLS-DA model for \texttt{ncomp\ =\ 2} to obtain 2D graphical outputs (Figure \ref{fig:MINT-plsda-indiv}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final.mint.plsda.stem }\OtherTok{\textless{}{-}} \FunctionTok{mint.plsda}\NormalTok{(}\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{Y =}\NormalTok{ Y, }\AttributeTok{study =}\NormalTok{ study, }\AttributeTok{ncomp =} \DecValTok{2}\NormalTok{)}

\CommentTok{\#final.mint.plsda.stem \# Lists the different functions}

\FunctionTok{plotIndiv}\NormalTok{(final.mint.plsda.stem, }\AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{title =} \StringTok{\textquotesingle{}MINT PLS{-}DA\textquotesingle{}}\NormalTok{, }
          \AttributeTok{subtitle =} \StringTok{\textquotesingle{}stem cell study\textquotesingle{}}\NormalTok{, }\AttributeTok{ellipse =}\NormalTok{ T)}
\end{Highlighting}
\end{Shaded}



The sample plot (Fig \ref{fig:MINT-plsda-indiv}) shows that \texttt{...colorize("blue",\ "fibroblast")} are separated on the first component. We observe that while deemed not crucial for an optimal discrimination, the second component seems to help separate \texttt{...colorize("orange",\ "hESC")} and \texttt{...colorize("grey",\ "hiPSC")} further. The effect of study after MINT modelling is not strong.

We can compare this output to a classical PLS-DA to visualise the study effect (Figure \ref{fig:stem-plsda-indiv}):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{plsda.stem }\OtherTok{\textless{}{-}} \FunctionTok{plsda}\NormalTok{(}\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{Y =}\NormalTok{ Y, }\AttributeTok{ncomp =} \DecValTok{2}\NormalTok{)}

\FunctionTok{plotIndiv}\NormalTok{(plsda.stem, }\AttributeTok{pch =}\NormalTok{ study,}
          \AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{, }\AttributeTok{title =} \StringTok{\textquotesingle{}Classic PLS{-}DA\textquotesingle{}}\NormalTok{,}
          \AttributeTok{legend.title =} \StringTok{\textquotesingle{}Cell type\textquotesingle{}}\NormalTok{, }\AttributeTok{legend.title.pch =} \StringTok{\textquotesingle{}Study\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



\hypertarget{mint:splsda}{%
\section{Example: MINT sPLS-DA}\label{mint:splsda}}

The MINT PLS-DA model shown earlier is built on all 400 genes in \(\boldsymbol X\), many of which may be uninformative to characterise the different classes. Here we aim to identify a small subset of genes that best discriminate the classes.

\hypertarget{number-of-variables-to-select}{%
\subsection{Number of variables to select}\label{number-of-variables-to-select}}

We can choose the \texttt{keepX} parameter using the \texttt{tune()} function for a MINT object. The function performs LOGOCV for different values of \texttt{test.keepX} provided on each component, and no repeat argument is needed. Based on the mean classification error rate (overall error rate or BER) and a centroids distance, we output the optimal number of variables \texttt{keepX} to be included in the final model.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{2543}\NormalTok{)  }\CommentTok{\# For a reproducible result here, remove for your own analyses}
\NormalTok{tune.mint.splsda.stem }\OtherTok{\textless{}{-}} \FunctionTok{tune}\NormalTok{(}\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{Y =}\NormalTok{ Y, }\AttributeTok{study =}\NormalTok{ study, }
                 \AttributeTok{ncomp =} \DecValTok{2}\NormalTok{, }\AttributeTok{test.keepX =} \FunctionTok{seq}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{100}\NormalTok{, }\DecValTok{1}\NormalTok{),}
                 \AttributeTok{method =} \StringTok{\textquotesingle{}mint.splsda\textquotesingle{}}\NormalTok{, }\CommentTok{\#Specify the method}
                 \AttributeTok{measure =} \StringTok{\textquotesingle{}BER\textquotesingle{}}\NormalTok{,}
                 \AttributeTok{dist =} \StringTok{"centroids.dist"}\NormalTok{)}

\CommentTok{\#tune.mint.splsda.stem \# Lists the different types of outputs}

\CommentTok{\# Mean error rate per component and per tested keepX value:}
\CommentTok{\#tune.mint.splsda.stem$error.rate[1:5,]}
\end{Highlighting}
\end{Shaded}

The optimal number of variables to select on each specified component:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{tune.mint.splsda.stem}\SpecialCharTok{$}\NormalTok{choice.keepX}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plot}\NormalTok{(tune.mint.splsda.stem)}
\end{Highlighting}
\end{Shaded}



The tuning plot in Figure \ref{fig:MINT-tune} indicates the optimal number of variables to select on component 1 (\texttt{...tune.mint.splsda.stem\$choice.keepX{[}1{]}}) and on component 2 (\texttt{...tune.mint.splsda.stem\$choice.keepX{[}2{]}}). In fact, whilst the BER decreases with the addition of component 2, the standard deviation remains large, and thus only one component is optimal. However, the addition of this second component is useful for the graphical outputs, and also to attempt to discriminate the hESC and hiPCS cell types.

Note:

\begin{itemize}
\tightlist
\item
  \emph{As shown in the quick start example, the tuning step can be omitted if you prefer to set arbitrary \texttt{keepX} values.}
\end{itemize}

\hypertarget{final-mint-spls-da-model}{%
\subsection{Final MINT sPLS-DA model}\label{final-mint-spls-da-model}}

Following the tuning results, our final model is as follows (we still choose a model with two components in order to obtain 2D graphics):

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{final.mint.splsda.stem }\OtherTok{\textless{}{-}} \FunctionTok{mint.splsda}\NormalTok{(}\AttributeTok{X =}\NormalTok{ X, }\AttributeTok{Y =}\NormalTok{ Y, }\AttributeTok{study =}\NormalTok{ study, }\AttributeTok{ncomp =} \DecValTok{2}\NormalTok{,  }
                              \AttributeTok{keepX =}\NormalTok{ tune.mint.splsda.stem}\SpecialCharTok{$}\NormalTok{choice.keepX)}

\CommentTok{\#mint.splsda.stem.final \# Lists useful functions that can be used with a MINT object}
\end{Highlighting}
\end{Shaded}

\hypertarget{mint:result:ncomp}{%
\subsection{Sample plots}\label{mint:result:ncomp}}

The samples can be projected on the global components or alternatively using the partial components from each study (Fig \ref{fig:MINT-indiv}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotIndiv}\NormalTok{(final.mint.splsda.stem, }\AttributeTok{study =} \StringTok{\textquotesingle{}global\textquotesingle{}}\NormalTok{, }\AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{, }
          \AttributeTok{title =} \StringTok{\textquotesingle{}Stem cells, MINT sPLS{-}DA\textquotesingle{}}\NormalTok{, }
          \AttributeTok{subtitle =} \StringTok{\textquotesingle{}Global\textquotesingle{}}\NormalTok{, }\AttributeTok{ellipse =}\NormalTok{ T)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotIndiv}\NormalTok{(final.mint.splsda.stem, }\AttributeTok{study =} \StringTok{\textquotesingle{}all.partial\textquotesingle{}}\NormalTok{, }\AttributeTok{legend =} \ConstantTok{TRUE}\NormalTok{, }
          \AttributeTok{title =} \StringTok{\textquotesingle{}Stem cells, MINT sPLS{-}DA\textquotesingle{}}\NormalTok{, }
          \AttributeTok{subtitle =} \FunctionTok{paste}\NormalTok{(}\StringTok{"Study"}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}



The visualisation of the partial components enables us to examine each study individually and check that the model is able to extract a good agreement between studies.

\hypertarget{mint:result:varplot}{%
\subsection{Variable plots}\label{mint:result:varplot}}

\hypertarget{correlation-circle-plot}{%
\subsubsection{Correlation circle plot}\label{correlation-circle-plot}}

We can examine our molecular signature selected with MINT sPLS-DA. The correlation circle plot, presented in Module 2, highlights the contribution of each selected transcript to each component (close to the large circle), and their correlation (clusters of variables) in Figure \ref{fig:MINT-var-col}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotVar}\NormalTok{(final.mint.splsda.stem)}
\end{Highlighting}
\end{Shaded}



We observe a \texttt{...colorize("pink",\ "subset\ of\ genes\ that\ are\ strongly\ correlated\ and\ negatively")} associated to component 1 (negative values on the x-axis), which are likely to characterise the groups of samples hiPSC and hESC, and a \texttt{...colorize("green",\ "subset\ of\ genes\ positively")} associated to component 1 that may characterise the fibroblast samples (and are negatively correlated to the previous group of genes).

Note:

\begin{itemize}
\tightlist
\item
  \emph{We can use the \texttt{var.name} argument to show gene name ID, as shown in Module 3 for PLS-DA.}
\end{itemize}

\hypertarget{clustered-image-maps}{%
\subsubsection{Clustered Image Maps}\label{clustered-image-maps}}

The Clustered Image Map represents the expression levels of the gene signature per sample, similar to a PLS-DA object (see Module 3). Here we use the default Euclidean distance and Complete linkage in Figure \ref{fig:MINT-cim} for a specific component (here 1):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# If facing margin issues, use either X11() or save the plot using the}
\CommentTok{\# arguments save and name.save}
\FunctionTok{cim}\NormalTok{(final.mint.splsda.stem, }\AttributeTok{comp =} \DecValTok{1}\NormalTok{, }\AttributeTok{margins=}\FunctionTok{c}\NormalTok{(}\DecValTok{10}\NormalTok{,}\DecValTok{5}\NormalTok{), }
    \AttributeTok{row.sideColors =} \FunctionTok{color.mixo}\NormalTok{(}\FunctionTok{as.numeric}\NormalTok{(Y)), }\AttributeTok{row.names =} \ConstantTok{FALSE}\NormalTok{,}
    \AttributeTok{title =} \StringTok{"MINT sPLS{-}DA, component 1"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



As expected and observed from the sample plot Figure \ref{fig:MINT-indiv}, we observe in the CIM that the expression of the genes selected on component 1 discriminates primarily the \texttt{...colorize("blue",\ "fibroblast")} vs.~the other cell types.

\hypertarget{relevance-networks}{%
\subsubsection{Relevance networks}\label{relevance-networks}}

Relevance networks can also be plotted for a PLS-DA object, but would only show the association between the selected genes and the cell type (dummy variable in \(\boldsymbol Y\) as an outcome category) as shown in Figure \ref{fig:MINT-network}. Only the variables selected on component 1 are shown (\texttt{comp\ =\ 1}):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# If facing margin issues, use either X11() or save the plot using the}
\CommentTok{\# arguments save and name.save}
\FunctionTok{network}\NormalTok{(final.mint.splsda.stem, }\AttributeTok{comp =} \DecValTok{1}\NormalTok{,}
        \AttributeTok{color.node =} \FunctionTok{c}\NormalTok{(}\FunctionTok{color.mixo}\NormalTok{(}\DecValTok{1}\NormalTok{), }\FunctionTok{color.mixo}\NormalTok{(}\DecValTok{2}\NormalTok{)), }
        \AttributeTok{shape.node =} \FunctionTok{c}\NormalTok{(}\StringTok{"rectangle"}\NormalTok{, }\StringTok{"circle"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}



\hypertarget{variable-selection-and-loading-plots}{%
\subsubsection{Variable selection and loading plots}\label{variable-selection-and-loading-plots}}

The \texttt{selectVar()} function outputs the selected transcripts on the first component along with their loading weight values. We consider variables as important in the model when their absolute loading weight value is high. In addition to this output, we can compare the stability of the selected features across studies using the \texttt{perf()} function, as shown in PLS-DA in Module 3.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Just a head}
\FunctionTok{head}\NormalTok{(}\FunctionTok{selectVar}\NormalTok{(final.mint.plsda.stem, }\AttributeTok{comp =} \DecValTok{1}\NormalTok{)}\SpecialCharTok{$}\NormalTok{value)}
\end{Highlighting}
\end{Shaded}

The \texttt{plotLoadings()} function displays the coefficient weight of each selected variable in each study and shows the agreement of the gene signature across studies (Figure \ref{fig:MINT-loading}). Colours indicate the class in which the mean expression value of each selected gene is maximal. For component 1, we obtain:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{plotLoadings}\NormalTok{(final.mint.splsda.stem, }\AttributeTok{contrib =} \StringTok{"max"}\NormalTok{, }\AttributeTok{method =} \StringTok{\textquotesingle{}mean\textquotesingle{}}\NormalTok{, }\AttributeTok{comp=}\DecValTok{1}\NormalTok{, }
             \AttributeTok{study=}\StringTok{"all.partial"}\NormalTok{, }\AttributeTok{title=}\StringTok{"Contribution on comp 1"}\NormalTok{, }
             \AttributeTok{subtitle =} \FunctionTok{paste}\NormalTok{(}\StringTok{"Study"}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{))}
\end{Highlighting}
\end{Shaded}



Several \texttt{...colorize("blue",\ "genes")} are consistently over-expressed on average in the \texttt{...colorize("blue",\ "fibroblast")} samples in each of the studies, however, we observe a less consistent pattern for the other genes that characterise \texttt{...colorize("grey",\ "hiPSC")}\} and \texttt{...colorize("orange",\ "hESC")}. This can be explained as the discrimination between both classes is challenging on component 1 (see sample plot in Figure \ref{fig:MINT-indiv}).

\hypertarget{mint:result:perf}{%
\subsection{Classification performance}\label{mint:result:perf}}

We assess the performance of the MINT sPLS-DA model with the \texttt{perf()} function. Since the previous tuning was conducted with the distance \texttt{centroids.dist}, the same distance is used to assess the performance of the final model. We do not need to specify the argument \texttt{nrepeat} as we use LOGOCV in the function.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)  }\CommentTok{\# For reproducible results here, remove for your own study}
\NormalTok{perf.mint.splsda.stem.final }\OtherTok{\textless{}{-}} \FunctionTok{perf}\NormalTok{(final.mint.plsda.stem, }\AttributeTok{dist =} \StringTok{\textquotesingle{}centroids.dist\textquotesingle{}}\NormalTok{)}

\NormalTok{perf.mint.splsda.stem.final}\SpecialCharTok{$}\NormalTok{global.error}
\end{Highlighting}
\end{Shaded}

The classification error rate per class is particularly insightful to understand which cell types are difficult to classify, hESC and hiPS - whose mixture can be explained for biological reasons.

\hypertarget{mint:detour}{%
\section{Take a detour}\label{mint:detour}}

\hypertarget{auc}{%
\subsection{AUC}\label{auc}}

An AUC plot for the integrated data can be obtained using the function \texttt{auroc()} (Fig \ref{fig:MINT-auc}).

Remember that the AUC incorporates measures of sensitivity and specificity for every possible cut-off of the predicted dummy variables. However, our PLS-based models rely on prediction distances, which can be seen as a determined optimal cut-off. Therefore, the ROC and AUC criteria may not be particularly insightful in relation to the performance evaluation of our supervised multivariate methods, but can complement the statistical analysis (from \citet{Roh17}).

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{auroc}\NormalTok{(final.mint.splsda.stem, }\AttributeTok{roc.comp =} \DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We can also obtain an AUC plot per study by specifying the argument \texttt{roc.study}:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{auroc}\NormalTok{(final.mint.splsda.stem, }\AttributeTok{roc.comp =} \DecValTok{1}\NormalTok{, }\AttributeTok{roc.study =} \StringTok{\textquotesingle{}2\textquotesingle{}}\NormalTok{)}
\end{Highlighting}
\end{Shaded}



\hypertarget{detour:mint:predict}{%
\subsection{Prediction on an external study}\label{detour:mint:predict}}

We use the \texttt{predict()} function to predict the class membership of new test samples from an external study. We provide an example where we set aside a particular study, train the MINT model on the remaining three studies, then predict on the test study. This process exactly reflects the inner workings of the \texttt{tune()} and \texttt{perf()} functions using LOGOCV.

Here during our model training on the three studies only, we assume we have performed the tuning steps described in this case study to choose \texttt{ncomp} and \texttt{keepX} (here set to arbitrary values to avoid overfitting):

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# We predict on study 3}
\NormalTok{indiv.test }\OtherTok{\textless{}{-}} \FunctionTok{which}\NormalTok{(study }\SpecialCharTok{==} \StringTok{"3"}\NormalTok{)}

\CommentTok{\# We train on the remaining studies, with pre{-}tuned parameters}
\NormalTok{mint.splsda.stem2 }\OtherTok{\textless{}{-}} \FunctionTok{mint.splsda}\NormalTok{(}\AttributeTok{X =}\NormalTok{ X[}\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(indiv.test), ], }
                                \AttributeTok{Y =}\NormalTok{ Y[}\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(indiv.test)], }
                                \AttributeTok{study =} \FunctionTok{droplevels}\NormalTok{(study[}\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(indiv.test)]), }
                                \AttributeTok{ncomp =} \DecValTok{1}\NormalTok{,  }
                                \AttributeTok{keepX =} \DecValTok{30}\NormalTok{)}

\NormalTok{mint.predict.stem }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(mint.splsda.stem2, }\AttributeTok{newdata =}\NormalTok{ X[indiv.test, ], }
                        \AttributeTok{dist =} \StringTok{"centroids.dist"}\NormalTok{,}
                        \AttributeTok{study.test =} \FunctionTok{factor}\NormalTok{(study[indiv.test]))}

\CommentTok{\# Store class prediction with a model with 1 comp}
\NormalTok{indiv.prediction }\OtherTok{\textless{}{-}}\NormalTok{ mint.predict.stem}\SpecialCharTok{$}\NormalTok{class}\SpecialCharTok{$}\NormalTok{centroids.dist[, }\DecValTok{1}\NormalTok{]}

\CommentTok{\# The confusion matrix compares the real subtypes with the predicted subtypes}
\NormalTok{conf.mat }\OtherTok{\textless{}{-}} \FunctionTok{get.confusion\_matrix}\NormalTok{(}\AttributeTok{truth =}\NormalTok{ Y[indiv.test],}
                     \AttributeTok{predicted =}\NormalTok{ indiv.prediction)}

\NormalTok{conf.mat}
\end{Highlighting}
\end{Shaded}

Here we have considered a trained model with one component, and compared the cell type prediction for the test study 3 with the known cell types. The classification error rate is relatively high, but potentially could be improved with a proper tuning, and a larger number of studies in the training set.

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Prediction error rate}
\NormalTok{(}\FunctionTok{sum}\NormalTok{(conf.mat) }\SpecialCharTok{{-}} \FunctionTok{sum}\NormalTok{(}\FunctionTok{diag}\NormalTok{(conf.mat)))}\SpecialCharTok{/}\FunctionTok{sum}\NormalTok{(conf.mat)}
\end{Highlighting}
\end{Shaded}

\hypertarget{session-information}{%
\chapter{Session Information}\label{session-information}}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sessionInfo}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## R Under development (unstable) (2022-10-11 r83083 ucrt)
## Platform: x86_64-w64-mingw32/x64 (64-bit)
## Running under: Windows 10 x64 (build 19044)
## 
## Matrix products: default
## 
## locale:
## [1] LC_COLLATE=English_Australia.utf8  LC_CTYPE=English_Australia.utf8   
## [3] LC_MONETARY=English_Australia.utf8 LC_NUMERIC=C                      
## [5] LC_TIME=English_Australia.utf8    
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## loaded via a namespace (and not attached):
##  [1] digest_0.6.30   bookdown_0.31   fastmap_1.1.0   xfun_0.35      
##  [5] magrittr_2.0.3  glue_1.6.2      stringr_1.5.0   knitr_1.41     
##  [9] htmltools_0.5.3 rmarkdown_2.18  lifecycle_1.0.3 cli_3.4.1      
## [13] vctrs_0.5.1     compiler_4.3.0  rstudioapi_0.14 tools_4.3.0    
## [17] evaluate_0.18   yaml_2.3.6      rlang_1.0.6     stringi_1.7.8
\end{verbatim}

  \bibliography{bibliography.bib}

\end{document}
